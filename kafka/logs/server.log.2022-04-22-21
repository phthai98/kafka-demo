[2022-04-22 21:25:26,610] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,614] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,627] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,627] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,627] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,628] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,632] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:25:26,632] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:25:26,632] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:25:26,632] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-04-22 21:25:26,638] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-04-22 21:25:26,653] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,654] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,654] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,655] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,655] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,655] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:25:26,655] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-04-22 21:25:26,674] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@62230c58 (org.apache.zookeeper.server.ServerMetrics)
[2022-04-22 21:25:26,679] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:25:26,695] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,695] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,696] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,696] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,697] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,698] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,698] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,699] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,700] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:26,700] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,326] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,328] INFO Server environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,337] INFO Server environment:java.version=11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,341] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,355] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,359] INFO Server environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,373] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,383] INFO Server environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,384] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,388] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,390] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,391] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,392] INFO Server environment:user.name=thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,393] INFO Server environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,394] INFO Server environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,395] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,397] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,400] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,402] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,403] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,411] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,412] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,413] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,414] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,420] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,426] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-04-22 21:25:31,431] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,432] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,439] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:25:31,440] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:25:31,443] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:25:31,444] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:25:31,445] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:25:31,446] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:25:31,447] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:25:31,450] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:25:31,458] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,458] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,459] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir D:\Kafka\kafka\data\zookeeper\version-2 snapdir D:\Kafka\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,505] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:25:31,509] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:25:31,512] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:25:31,520] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:25:31,568] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:25:31,569] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:25:31,573] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:25:31,573] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:25:31,584] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-04-22 21:25:31,616] INFO Reading snapshot D:\Kafka\kafka\data\zookeeper\version-2\snapshot.b2 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-04-22 21:25:31,631] INFO The digest in the snapshot has digest version of 2, , with zxid as 0xb2, and digest value as 300774589312 (org.apache.zookeeper.server.DataTree)
[2022-04-22 21:25:31,689] INFO 39 txns loaded in 25 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:25:31,689] INFO Snapshot loaded in 115 ms, highest zxid is 0xd9, digest is 304962548522 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:25:31,693] INFO Snapshotting: 0xd9 to D:\Kafka\kafka\data\zookeeper\version-2\snapshot.d9 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:25:31,701] INFO Snapshot taken in 8 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:31,728] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-04-22 21:25:31,730] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-04-22 21:25:31,762] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-04-22 21:25:31,765] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-04-22 21:25:33,241] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:25:33,241] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:25:33,252] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:25:33,878] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:25:33,879] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:25:33,879] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:25:34,024] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:25:34,024] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:25:34,024] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:25:34,025] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:25:34,025] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:25:34,026] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:25:34,050] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:34,050] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:34,050] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:38,670] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,670] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,670] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,671] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,671] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,671] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,672] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,673] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,679] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,679] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,680] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,683] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,684] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,684] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,685] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,698] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,699] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,700] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,701] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,702] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,704] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,705] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,705] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,708] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,708] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,709] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,711] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,712] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,713] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,713] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,714] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,716] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,718] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,720] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,725] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,726] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,726] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,730] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,731] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,730] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,738] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,737] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,738] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,744] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,750] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,751] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,753] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:38,772] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:25:38,774] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:25:38,774] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:25:38,786] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,786] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,786] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,790] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:38,789] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:38,790] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:38,821] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,822] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,823] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,823] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,824] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,825] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,834] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:56813, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,835] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:56814, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,836] INFO Socket connection established, initiating session, client: /127.0.0.1:56815, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,855] INFO Creating new log file: log.da (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-04-22 21:25:38,869] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100005b4ca10002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,869] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005b4ca10000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,869] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005b4ca10001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:38,879] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:38,880] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:38,881] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:39,036] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:39,036] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:39,036] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:39,311] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:25:39,311] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:25:39,313] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:25:39,323] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:25:39,324] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:25:39,328] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:25:39,333] WARN No meta.properties file under dir D:\Kafka\kafka\data\kafka-2\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2022-04-22 21:25:39,464] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:25:39,480] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:25:39,489] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:25:39,496] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:25:39,508] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:25:39,528] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:25:39,589] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,590] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,600] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,600] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,604] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,604] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,605] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,609] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,609] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,610] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,610] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,614] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:39,702] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-2) (kafka.log.LogManager)
[2022-04-22 21:25:39,702] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-1) (kafka.log.LogManager)
[2022-04-22 21:25:39,702] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:39,714] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:25:39,714] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:25:39,714] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:25:39,737] INFO Loaded 0 logs in 35ms. (kafka.log.LogManager)
[2022-04-22 21:25:39,738] INFO Loaded 0 logs in 36ms. (kafka.log.LogManager)
[2022-04-22 21:25:39,739] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:25:39,740] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:25:39,747] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:25:39,747] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:25:39,891] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:39,896] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:39,900] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:39,906] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:39,908] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:39,969] INFO [ProducerStateManager partition=my-first-topic-0] Wrote producer snapshot at offset 4 with 0 producer ids in 6 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,036] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,036] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,040] INFO [ProducerStateManager partition=my-first-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,051] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 13ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,113] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-0, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 342ms (1/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,124] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,125] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,126] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,128] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:40,129] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,138] INFO [ProducerStateManager partition=my-first-topic-1] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,147] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,147] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,149] INFO [ProducerStateManager partition=my-first-topic-1] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,152] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,160] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-1, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 46ms (2/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,169] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,170] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,171] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,173] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:40,175] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,186] INFO [ProducerStateManager partition=my-first-topic-2] Wrote producer snapshot at offset 7 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,194] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,195] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,197] INFO [ProducerStateManager partition=my-first-topic-2] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot,7)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,200] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,208] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-2, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=7) with 1 segments in 48ms (3/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,219] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,220] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,222] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,224] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:40,226] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,235] INFO [ProducerStateManager partition=my-fisrt-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,243] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,243] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,245] INFO [ProducerStateManager partition=my-fisrt-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,249] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,265] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-fisrt-topic-0, topicId=u_QBLZWtQtSU7aAZPPbqqA, topic=my-fisrt-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 56ms (4/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,275] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,276] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,277] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,279] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:40,280] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,290] INFO [ProducerStateManager partition=my-second-topic-0] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,298] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,298] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,300] INFO [ProducerStateManager partition=my-second-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,305] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,317] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-second-topic-0, topicId=rbnejGrRQJCw5AB-qCDQNw, topic=my-second-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 51ms (5/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,323] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,324] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,324] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,325] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,335] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,336] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,337] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,348] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-0, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (6/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,355] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,357] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,357] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,358] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,366] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,366] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,367] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,372] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-1, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (7/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,377] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,380] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,381] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,381] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,388] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,388] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,389] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,394] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-10, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (8/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,401] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,402] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,402] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,403] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,409] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,409] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,410] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,417] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-11, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (9/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,422] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,423] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,423] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,424] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,432] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,432] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,433] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,439] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-12, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (10/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,447] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,448] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,449] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,449] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:40,449] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,484] INFO [ProducerStateManager partition=__consumer_offsets-13] Wrote producer snapshot at offset 831 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,490] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 831 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,490] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,491] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot,831)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,494] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,498] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-13, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=831) with 1 segments in 58ms (11/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,504] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,506] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,506] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,507] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,515] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,516] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,516] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,522] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-14, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (12/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,527] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,527] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,528] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:40,528] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:40,528] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,533] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,540] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,540] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,541] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,546] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-15, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (13/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,552] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,553] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,554] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,555] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,563] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,563] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,564] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,569] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-16, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (14/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,574] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,574] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,575] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,575] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,584] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,585] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,586] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,591] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-17, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (15/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,597] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,598] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,598] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,599] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,609] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,609] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,610] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,617] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-18, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (16/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,623] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,624] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,624] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,625] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,635] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,635] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,636] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,642] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-19, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (17/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,650] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,651] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,652] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,653] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,663] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,664] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,665] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,671] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-2, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 28ms (18/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,678] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,679] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,679] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,680] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,688] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,688] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,689] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,694] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-20, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (19/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,700] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,701] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,701] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,702] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,710] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,710] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,712] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,717] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-21, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (20/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,724] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,725] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,726] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,727] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,736] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,736] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,737] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,742] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-22, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (21/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,749] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,750] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,751] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,752] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,761] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,762] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,763] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,769] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-23, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (22/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,776] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,777] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,779] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,779] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,788] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,789] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,790] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,795] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-24, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (23/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,803] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,805] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,806] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,807] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,817] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,817] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,818] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,825] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-25, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (24/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,832] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,833] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,833] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,835] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,846] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,846] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,847] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:25:40,847] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,851] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:25:40,855] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-26, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (25/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,856] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-04-22 21:25:40,859] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-04-22 21:25:40,862] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,863] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,863] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,864] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:40,865] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,879] INFO [ProducerStateManager partition=__consumer_offsets-27] Wrote producer snapshot at offset 669 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,885] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 669 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,885] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,886] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot,669)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:40,889] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,892] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-27, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=669) with 1 segments in 36ms (26/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,899] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,901] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,901] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,902] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:25:40,902] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:25:40,902] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,914] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,916] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:40,916] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:40,915] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,917] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,924] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-28, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 31ms (27/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,929] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,929] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,930] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,930] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,939] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,939] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,940] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,943] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-29, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (28/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,949] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,949] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,950] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,950] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,953] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,955] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,956] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,956] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,956] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,956] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,956] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,965] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:40,966] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,967] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,970] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,974] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-3, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (29/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:40,980] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:40,981] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:40,983] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:40,984] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,984] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,985] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,993] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,993] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:40,996] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,002] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-30, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (30/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,007] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,007] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,008] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,009] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,017] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,017] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,018] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,021] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-31, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (31/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,026] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,027] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,027] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,028] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,034] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,034] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,035] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,039] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-32, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (32/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,045] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,045] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,046] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,047] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:41,047] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,052] INFO [ProducerStateManager partition=__consumer_offsets-33] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:41,056] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,057] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,058] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:41,060] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,063] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-33, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 24ms (33/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,067] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,067] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,068] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,069] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,074] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,075] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,075] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,079] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-34, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (34/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,084] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,084] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,085] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,086] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,092] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,092] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,093] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,097] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-35, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (35/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,101] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,101] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,102] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,104] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,110] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,110] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,112] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,115] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-36, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (36/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,119] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,120] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,120] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,121] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,127] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,127] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,128] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,131] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-37, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (37/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,135] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,136] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,137] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,137] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,143] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,143] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,144] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,147] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-38, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (38/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,151] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,152] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,152] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,153] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,158] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,159] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,159] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,162] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-39, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (39/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,166] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,168] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,169] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,169] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,175] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,176] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,176] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,180] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-4, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (40/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,184] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,185] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,185] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,186] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,192] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,192] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,193] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,196] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-40, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (41/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,201] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,201] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,202] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,202] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,208] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,209] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,209] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,213] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-41, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (42/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,217] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,218] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,218] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,219] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,225] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,225] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,226] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,230] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-42, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (43/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,235] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,236] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,236] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,237] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,243] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,244] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,245] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,248] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-43, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (44/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,253] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,253] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,254] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,254] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,260] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,261] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,262] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,267] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-44, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (45/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,271] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,272] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,272] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,273] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,279] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,279] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,280] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,283] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-45, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (46/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,287] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,288] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,288] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,289] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,295] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,295] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,296] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,299] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-46, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (47/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,303] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,303] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,304] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,304] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,311] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,311] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,312] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,315] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-47, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (48/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,319] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,319] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,320] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,321] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,326] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,327] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,328] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,331] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-48, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (49/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,335] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,335] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,336] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,337] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,343] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,343] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,344] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,347] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-49, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (50/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,352] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,353] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,353] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,354] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:25:41,354] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,361] INFO [ProducerStateManager partition=__consumer_offsets-5] Wrote producer snapshot at offset 3 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:25:41,366] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,366] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,367] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:25:41,368] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,371] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-5, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 23ms (51/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,375] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,376] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,376] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,377] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,383] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,383] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,384] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,387] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-6, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (52/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,391] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,392] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,392] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,393] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,399] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,399] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,400] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,403] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-7, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (53/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,407] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,408] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,408] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,409] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,415] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,415] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,416] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,419] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-8, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (54/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,424] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:25:41,424] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,425] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,426] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,432] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,432] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,433] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:25:41,436] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-9, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (55/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:25:41,438] INFO Loaded 55 logs in 1735ms. (kafka.log.LogManager)
[2022-04-22 21:25:41,440] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:25:41,441] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:25:41,799] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:41,926] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:25:41,932] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-04-22 21:25:41,964] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:25:41,973] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:41,997] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:42,000] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:42,000] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:42,002] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:42,018] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:45,685] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:25:45,695] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:25:45,723] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '72058574526611458' does not match current session '72057986165571585' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-04-22 21:25:45,726] INFO Stat of the created znode at /brokers/ids/2 is: 264,264,1650637545712,1650637545712,1,0,0,72057986165571586,226,0,264
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:25:45,729] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9094, czxid (broker epoch): 264 (kafka.zk.KafkaZkClient)
[2022-04-22 21:25:45,732] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-04-22 21:25:45,736] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:25:45,739] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-04-22 21:25:45,744] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-04-22 21:25:45,751] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-04-22 21:25:45,754] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:45,756] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:45,756] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:45,758] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:25:45,761] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:25:45,762] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-04-22 21:25:45,763] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-04-22 21:25:45,764] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,840] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,851] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,853] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,860] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,860] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,862] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,876] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,876] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,878] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:45,884] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:25:45,906] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:25:45,938] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:25:45,945] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:25:45,946] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:25:45,994] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,020] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:25:46,057] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:25:46,065] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:25:46,066] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:25:46,067] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,067] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,070] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,077] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:25:46,077] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:25:46,079] INFO Kafka startTimeMs: 1650637546067 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:25:46,082] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,082] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-04-22 21:25:46,082] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,098] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-04-22 21:25:46,101] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:46,102] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:46,102] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:46,111] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-04-22 21:25:46,113] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:46,116] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:46,116] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:46,119] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-04-22 21:25:46,121] INFO Shutting down. (kafka.log.LogManager)
[2022-04-22 21:25:46,155] INFO Shutdown complete. (kafka.log.LogManager)
[2022-04-22 21:25:46,157] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:46,158] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:46,158] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:46,163] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:46,275] INFO Session: 0x100005b4ca10001 closed (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:46,275] INFO EventThread shut down for session: 0x100005b4ca10001 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:46,277] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:46,280] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:46,683] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:25:46,685] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:46,685] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:46,685] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:46,706] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72058574526611456' does not match current session '72057986165571584' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-04-22 21:25:46,713] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-04-22 21:25:46,716] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:25:46,717] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-04-22 21:25:46,723] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-04-22 21:25:46,731] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-04-22 21:25:46,732] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:46,733] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:46,733] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:25:46,735] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:25:46,737] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:25:46,737] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-04-22 21:25:46,738] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-04-22 21:25:46,739] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,893] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,893] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:46,895] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,099] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,099] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,101] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,304] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,304] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,305] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,320] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,320] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:25:47,331] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-04-22 21:25:47,331] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:47,332] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:47,332] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:47,339] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-04-22 21:25:47,340] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:47,341] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:47,341] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:47,343] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-04-22 21:25:47,344] INFO Shutting down. (kafka.log.LogManager)
[2022-04-22 21:25:47,506] INFO Shutdown complete. (kafka.log.LogManager)
[2022-04-22 21:25:47,507] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:47,508] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:47,508] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:25:47,512] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:47,617] INFO Session: 0x100005b4ca10000 closed (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:25:47,617] INFO EventThread shut down for session: 0x100005b4ca10000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:25:47,619] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:25:47,621] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:47,695] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:47,695] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:47,695] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:47,695] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:47,699] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:47,696] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,708] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,708] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,708] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,708] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,712] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,714] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,724] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,724] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:48,727] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-04-22 21:25:48,761] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-04-22 21:25:48,762] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:25:48,763] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:25:48,764] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:25:48,767] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-04-22 21:25:48,773] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:25:48,773] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-04-22 21:25:48,773] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-04-22 21:25:48,775] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:25:49,715] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:49,715] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:49,717] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:50,728] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:50,728] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:25:50,732] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-04-22 21:25:50,762] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-04-22 21:25:50,769] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:25:50,770] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:25:50,771] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:25:50,774] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-04-22 21:25:50,781] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:25:50,782] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-04-22 21:25:50,783] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-04-22 21:25:50,784] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:25:51,317] INFO Expiring session 0x10000e449ae0002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:51,319] INFO Expiring session 0x10000e449ae0000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:25:51,645] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:25:51,692] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:26:03,318] INFO Expiring session 0x10000e449ae0003, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:03,319] INFO Expiring session 0x10000e449ae0004, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:40,009] WARN Session 0x100005b4ca10002 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:233)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:74)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-04-22 21:26:41,858] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:41,859] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:43,811] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,813] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,824] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,825] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,825] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,825] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,828] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:26:43,829] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:26:43,829] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:26:43,829] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-04-22 21:26:43,834] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-04-22 21:26:43,847] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,848] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,848] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,849] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,849] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,849] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:26:43,849] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-04-22 21:26:43,862] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@3d1cfad4 (org.apache.zookeeper.server.ServerMetrics)
[2022-04-22 21:26:43,867] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:26:43,878] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,879] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,879] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,880] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,881] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,881] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,882] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,883] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,883] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,884] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:43,893] WARN Session 0x100005b4ca10002 for sever localhost/0:0:0:0:0:0:0:1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-04-22 21:26:45,541] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:45,542] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:47,575] WARN Session 0x100005b4ca10002 for sever localhost/0:0:0:0:0:0:0:1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused: no further information
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:779)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-04-22 21:26:48,497] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,498] INFO Server environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,500] INFO Server environment:java.version=11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,503] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,503] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,504] INFO Server environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,506] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,508] INFO Server environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,509] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,509] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,510] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,511] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,511] INFO Server environment:user.name=thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,516] INFO Server environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,516] INFO Server environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,517] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,518] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,519] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,520] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,520] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,521] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,522] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,522] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,523] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,524] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,526] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-04-22 21:26:48,528] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,530] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,532] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:26:48,533] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:26:48,534] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:26:48,534] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:26:48,535] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:26:48,536] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:26:48,536] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:26:48,537] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:26:48,541] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,542] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,543] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir D:\Kafka\kafka\data\zookeeper\version-2 snapdir D:\Kafka\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,570] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:26:48,572] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:26:48,575] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:26:48,582] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:26:48,619] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:26:48,619] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:26:48,624] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:26:48,625] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:26:48,631] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-04-22 21:26:48,640] INFO Reading snapshot D:\Kafka\kafka\data\zookeeper\version-2\snapshot.d9 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-04-22 21:26:48,650] INFO The digest in the snapshot has digest version of 2, , with zxid as 0xd9, and digest value as 304962548522 (org.apache.zookeeper.server.DataTree)
[2022-04-22 21:26:48,682] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-04-22 21:26:48,693] INFO 111 txns loaded in 27 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:26:48,694] INFO Snapshot loaded in 70 ms, highest zxid is 0x148, digest is 293118972486 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:26:48,695] INFO Snapshotting: 0x148 to D:\Kafka\kafka\data\zookeeper\version-2\snapshot.148 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:26:48,701] INFO Snapshot taken in 6 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:26:48,718] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-04-22 21:26:48,718] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-04-22 21:26:48,743] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-04-22 21:26:48,933] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:48,934] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:48,936] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:56979, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:26:48,955] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005b4ca10002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:09,221] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:27:09,232] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:27:09,234] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:27:09,792] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:27:09,808] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:27:09,843] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:27:09,923] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:27:09,924] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:27:09,938] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:27:09,939] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:27:09,946] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:09,961] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:09,963] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:27:09,964] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:27:09,984] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,569] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,569] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,569] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,570] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,570] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,570] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,571] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,571] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,571] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,571] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,572] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,577] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,578] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,580] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,578] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,581] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,582] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,583] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,585] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,586] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,585] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,599] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,599] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,600] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,604] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,605] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,605] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,608] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,609] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,610] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,612] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,613] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,614] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,614] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,618] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,621] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,617] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,623] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,623] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,626] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,627] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,632] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,628] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,632] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,636] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,632] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,641] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,638] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,643] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,652] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:14,660] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:27:14,666] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:27:14,671] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,674] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:27:14,675] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,677] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,683] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,688] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,690] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,693] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,693] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,698] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,700] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:57755, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,700] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,706] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:57756, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,708] INFO Creating new log file: log.149 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-04-22 21:27:14,706] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,713] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,719] INFO Socket connection established, initiating session, client: /127.0.0.1:57757, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,721] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005c79650000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,724] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005c79650001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,730] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,734] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,734] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100005c79650002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:14,742] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:14,876] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:27:14,876] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:27:14,879] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:27:15,118] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:27:15,118] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:27:15,128] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:27:15,131] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:27:15,132] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:27:15,140] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:27:15,279] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:27:15,284] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:27:15,293] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:27:15,307] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:27:15,316] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:27:15,325] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:27:15,391] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,395] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,399] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,402] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,405] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,408] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,395] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,415] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,415] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,420] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,421] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,423] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,457] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in D:\Kafka\kafka\data\kafka-2. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-04-22 21:27:15,462] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:27:15,470] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:27:15,472] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:27:15,472] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:27:15,474] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:15,493] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-1) (kafka.log.LogManager)
[2022-04-22 21:27:15,501] INFO Skipping recovery for all logs in D:\Kafka\kafka\data\kafka-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:27:15,508] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,516] INFO Skipping recovery for all logs in D:\Kafka\kafka\data\kafka since clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:27:15,525] INFO Loaded 0 logs in 31ms. (kafka.log.LogManager)
[2022-04-22 21:27:15,526] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:27:15,534] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:27:15,592] INFO Session: 0x100005c79650001 closed (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:27:15,593] INFO EventThread shut down for session: 0x100005c79650001 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:27:15,598] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:27:15,599] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:15,717] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,719] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,723] INFO [ProducerStateManager partition=my-first-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:15,746] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 26ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,777] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-0, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 221ms (1/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,794] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,794] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,795] INFO [ProducerStateManager partition=my-first-topic-1] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:15,797] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,802] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-1, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 23ms (2/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,818] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,818] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,820] INFO [ProducerStateManager partition=my-first-topic-2] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot,7)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:15,822] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,828] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-2, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=7) with 1 segments in 25ms (3/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,841] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,843] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,845] INFO [ProducerStateManager partition=my-fisrt-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:15,846] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,851] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-fisrt-topic-0, topicId=u_QBLZWtQtSU7aAZPPbqqA, topic=my-fisrt-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 23ms (4/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,866] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,867] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,868] INFO [ProducerStateManager partition=my-second-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:15,870] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,874] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-second-topic-0, topicId=rbnejGrRQJCw5AB-qCDQNw, topic=my-second-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 22ms (5/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,882] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,889] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-0, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (6/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,898] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,903] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-1, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (7/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,910] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,914] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-10, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,921] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,927] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-11, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (9/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,934] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,938] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-12, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (10/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,954] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 831 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,955] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,956] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot,831)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:15,957] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,960] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-13, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=831) with 1 segments in 21ms (11/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,966] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,970] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-14, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (12/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,977] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,979] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-15, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (13/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,985] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:15,989] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-16, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (14/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:15,998] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,003] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-17, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (15/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,012] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,015] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-18, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (16/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,021] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,025] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-19, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (17/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,031] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,035] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-2, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (18/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,040] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,044] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-20, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (19/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,050] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,053] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-21, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (20/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,056] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:16,060] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,063] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-22, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (21/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,068] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,071] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-23, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (22/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,077] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,080] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-24, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (23/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,086] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,088] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-25, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (24/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,094] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,097] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-26, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (25/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,109] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 669 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,110] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,111] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot,669)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:16,113] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,116] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-27, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=669) with 1 segments in 19ms (26/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,121] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,124] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-28, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (27/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,130] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,132] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-29, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (28/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,137] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,139] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-3, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (29/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,146] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,149] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-30, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (30/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,154] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,157] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-31, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (31/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,164] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,167] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-32, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (32/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,178] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,179] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,180] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:16,181] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,183] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-33, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 16ms (33/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,189] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,193] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-34, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (34/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,199] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,201] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-35, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (35/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,208] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,211] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-36, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (36/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,217] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,219] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-37, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (37/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,228] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,230] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-38, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (38/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,238] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,240] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-39, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (39/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,248] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,251] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-4, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (40/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,258] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,261] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-40, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (41/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,268] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,271] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-41, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (42/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,278] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,281] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-42, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (43/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,288] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,291] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-43, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (44/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,297] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,299] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-44, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (45/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,305] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,307] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-45, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (46/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,312] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,314] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-46, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (47/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,318] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:27:16,319] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,322] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-47, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (48/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,325] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-04-22 21:27:16,327] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,329] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-48, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (49/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,335] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,337] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-49, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (50/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,350] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,351] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,352] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:27:16,353] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,355] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-5, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 17ms (51/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,361] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,365] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-6, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (52/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,368] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:27:16,371] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,373] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-7, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (53/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,379] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,380] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:16,382] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-8, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (54/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,386] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:27:16,388] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-9, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (55/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:27:16,392] INFO Loaded 55 logs in 885ms. (kafka.log.LogManager)
[2022-04-22 21:27:16,394] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:27:16,395] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:27:16,407] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:16,407] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:16,411] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:16,413] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,415] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,417] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,418] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,423] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:16,423] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:16,425] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:16,438] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:27:16,774] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:16,908] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:27:16,914] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-04-22 21:27:16,947] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:27:16,959] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:16,986] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,988] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,988] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:16,991] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:17,008] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:27:17,426] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:17,426] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:17,429] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:18,439] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:18,439] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:27:18,444] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:27:18,444] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:27:18,445] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:27:18,451] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-04-22 21:27:18,458] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:18,460] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-04-22 21:27:18,461] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-04-22 21:27:18,463] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:27:21,121] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:27:21,159] INFO Stat of the created znode at /brokers/ids/1 is: 375,375,1650637641142,1650637641142,1,0,0,72057991211581442,226,0,375
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:27:21,161] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9093, czxid (broker epoch): 375 (kafka.zk.KafkaZkClient)
[2022-04-22 21:27:21,269] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,277] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,279] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,302] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:21,323] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:21,351] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:27:21,357] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:27:21,358] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:27:21,403] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,427] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:27:21,462] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:27:21,469] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:27:21,470] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:27:21,479] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:21,479] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:21,480] INFO Kafka startTimeMs: 1650637641470 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:21,483] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-04-22 21:27:21,632] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:21,645] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:21,689] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:27:21,719] INFO Stat of the created znode at /brokers/ids/0 is: 376,376,1650637641706,1650637641706,1,0,0,72057991211581440,226,0,376
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:27:21,721] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9092, czxid (broker epoch): 376 (kafka.zk.KafkaZkClient)
[2022-04-22 21:27:21,858] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,867] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,868] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:21,892] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:21,912] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:21,948] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:27:21,954] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:27:21,955] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:27:22,002] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:27:22,030] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:27:22,065] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:27:22,073] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:27:22,074] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:27:22,083] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:22,084] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:22,085] INFO Kafka startTimeMs: 1650637642075 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:27:22,090] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-04-22 21:27:22,217] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:22,247] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:27:22,267] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,268] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,268] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,269] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,270] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,271] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,272] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,273] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,274] INFO [Partition my-first-topic-2 broker=0] Log loaded for partition my-first-topic-2 with initial high watermark 7 (kafka.cluster.Partition)
[2022-04-22 21:27:22,275] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,276] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,276] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,278] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,278] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,279] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,285] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,286] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,287] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Partition)
[2022-04-22 21:27:22,287] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,289] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,289] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,290] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,291] INFO [Partition my-fisrt-topic-0 broker=0] Log loaded for partition my-fisrt-topic-0 with initial high watermark 1 (kafka.cluster.Partition)
[2022-04-22 21:27:22,292] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 669 (kafka.cluster.Partition)
[2022-04-22 21:27:22,292] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,294] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,294] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,295] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 3 (kafka.cluster.Partition)
[2022-04-22 21:27:22,300] INFO [Partition my-first-topic-0 broker=0] Log loaded for partition my-first-topic-0 with initial high watermark 4 (kafka.cluster.Partition)
[2022-04-22 21:27:22,300] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,301] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,302] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,303] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,304] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,305] INFO [Partition my-second-topic-0 broker=0] Log loaded for partition my-second-topic-0 with initial high watermark 2 (kafka.cluster.Partition)
[2022-04-22 21:27:22,306] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,307] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,307] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,308] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,309] INFO [Partition my-first-topic-1 broker=0] Log loaded for partition my-first-topic-1 with initial high watermark 4 (kafka.cluster.Partition)
[2022-04-22 21:27:22,310] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,311] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,316] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,317] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,317] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,318] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,318] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,320] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,320] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,321] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,322] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,322] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,323] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,324] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:27:22,325] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 831 (kafka.cluster.Partition)
[2022-04-22 21:27:22,374] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, my-second-topic-0, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, my-fisrt-topic-0, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, my-first-topic-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, my-first-topic-2, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, my-first-topic-1, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:27:22,555] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,556] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,559] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,559] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,560] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,561] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,562] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,563] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,563] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,564] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,564] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,565] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,566] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,566] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 8 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,571] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 12 milliseconds for epoch 2, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,572] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 11 milliseconds for epoch 2, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,572] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,573] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 11 milliseconds for epoch 2, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,574] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 11 milliseconds for epoch 2, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,575] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,576] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 11 milliseconds for epoch 2, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,576] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,577] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 12 milliseconds for epoch 2, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,577] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,578] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 9 milliseconds for epoch 2, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,578] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 7 milliseconds for epoch 2, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,580] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,581] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 6 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,581] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 5 milliseconds for epoch 2, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,586] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 7 milliseconds for epoch 2, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,587] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,588] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 7 milliseconds for epoch 2, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,588] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,589] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 3 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,589] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,590] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,591] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,592] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds for epoch 2, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,593] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,594] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,595] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,596] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,596] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,597] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,598] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,601] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,602] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,603] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,604] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,604] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,605] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,606] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,607] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,609] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,609] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,610] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,611] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,611] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,612] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,613] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,613] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,614] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,618] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,618] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,619] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,619] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,620] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,620] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,621] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,622] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,622] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,623] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,624] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,624] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,625] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,625] INFO Loaded member MemberMetadata(memberId=console-consumer-2ea4b850-b99e-40be-b52c-d81b3bb1d42a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,626] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,628] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,628] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,629] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,630] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,633] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,634] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,635] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,635] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,636] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,637] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,638] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,638] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,639] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,639] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,640] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,641] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,642] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,643] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,643] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,643] INFO Loaded member MemberMetadata(memberId=console-consumer-341e2672-61f6-4e3d-90ca-ad1834dc410e, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,644] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,645] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,645] INFO Loaded member MemberMetadata(memberId=console-consumer-2ea4b850-b99e-40be-b52c-d81b3bb1d42a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,659] INFO Loaded member MemberMetadata(memberId=console-consumer-341e2672-61f6-4e3d-90ca-ad1834dc410e, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,661] INFO Loaded member MemberMetadata(memberId=console-consumer-af370b12-03a2-4453-bdd7-ee2bd75a61bc, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,671] INFO [GroupCoordinator 0]: Loading group metadata for my-first-app with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,676] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 81 milliseconds for epoch 2, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,677] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 81 milliseconds for epoch 2, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,678] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 80 milliseconds for epoch 2, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,680] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 78 milliseconds for epoch 2, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,684] INFO Loaded member MemberMetadata(memberId=console-consumer-b7ed5905-bf7f-4515-b7d4-81a2e8d11554, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-45122 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,685] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 81 milliseconds for epoch 2, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,686] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 81 milliseconds for epoch 2, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 81 milliseconds for epoch 2, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,688] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 81 milliseconds for epoch 2, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,688] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 79 milliseconds for epoch 2, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,689] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 79 milliseconds for epoch 2, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 79 milliseconds for epoch 2, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 77 milliseconds for epoch 2, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,691] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 77 milliseconds for epoch 2, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,691] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 73 milliseconds for epoch 2, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,692] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 73 milliseconds for epoch 2, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,693] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 73 milliseconds for epoch 2, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,693] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 71 milliseconds for epoch 2, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,694] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 71 milliseconds for epoch 2, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,698] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 74 milliseconds for epoch 2, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,699] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 73 milliseconds for epoch 2, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,699] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 71 milliseconds for epoch 2, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,700] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 71 milliseconds for epoch 2, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,700] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 70 milliseconds for epoch 2, of which 70 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,701] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 67 milliseconds for epoch 2, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,702] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 67 milliseconds for epoch 2, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,705] INFO Loaded member MemberMetadata(memberId=console-consumer-3d3ebe95-d5db-4582-b0db-577c0131baf8, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-second-app with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,706] INFO Loaded member MemberMetadata(memberId=console-consumer-24d030c2-59fc-4002-bcdb-1ba10eb26cb9, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-second-app with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,711] INFO [GroupCoordinator 0]: Loading group metadata for my-second-app with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:27:22,713] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 77 milliseconds for epoch 2, of which 66 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,714] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 76 milliseconds for epoch 2, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,717] INFO Loaded member MemberMetadata(memberId=console-consumer-05fc5b3f-7e86-4581-af95-f32bf52a57d0, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-24592 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:27:22,718] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 79 milliseconds for epoch 2, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,719] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 79 milliseconds for epoch 2, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,719] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 78 milliseconds for epoch 2, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,720] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 78 milliseconds for epoch 2, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,721] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 77 milliseconds for epoch 2, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:27:22,721] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 75 milliseconds for epoch 2, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:29:29,857] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,859] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,871] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,871] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,872] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,872] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,874] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:29:29,875] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:29:29,875] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:29:29,875] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-04-22 21:29:29,880] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-04-22 21:29:29,894] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,895] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,895] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,895] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,896] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,896] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:29:29,896] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-04-22 21:29:29,910] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@3d1cfad4 (org.apache.zookeeper.server.ServerMetrics)
[2022-04-22 21:29:29,914] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:29:29,925] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,925] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,926] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,926] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,927] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,928] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,928] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,929] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,929] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:29,930] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,480] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,481] INFO Server environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,484] INFO Server environment:java.version=11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,484] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,488] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,488] INFO Server environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,490] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,491] INFO Server environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,492] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,492] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,493] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,494] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,494] INFO Server environment:user.name=thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,495] INFO Server environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,501] INFO Server environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,502] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,502] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,503] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,504] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,505] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,505] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,506] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,507] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,508] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,509] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,511] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-04-22 21:29:34,515] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,515] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,518] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:29:34,518] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:29:34,521] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:29:34,521] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:29:34,522] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:29:34,522] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:29:34,523] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:29:34,524] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:29:34,528] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,530] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,530] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir D:\Kafka\kafka\data\zookeeper\version-2 snapdir D:\Kafka\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,552] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:29:34,554] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:29:34,557] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:29:34,562] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:29:34,599] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:29:34,599] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:29:34,603] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:29:34,603] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:29:34,610] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-04-22 21:29:34,618] INFO Reading snapshot D:\Kafka\kafka\data\zookeeper\version-2\snapshot.148 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-04-22 21:29:34,628] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x148, and digest value as 293118972486 (org.apache.zookeeper.server.DataTree)
[2022-04-22 21:29:34,668] INFO 103 txns loaded in 22 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:29:34,669] INFO Snapshot loaded in 65 ms, highest zxid is 0x1af, digest is 313946948505 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:29:34,671] INFO Snapshotting: 0x1af to D:\Kafka\kafka\data\zookeeper\version-2\snapshot.1af (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:29:34,677] INFO Snapshot taken in 5 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:34,693] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-04-22 21:29:34,694] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-04-22 21:29:34,716] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-04-22 21:29:34,718] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-04-22 21:29:39,768] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:29:40,303] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:29:40,407] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:29:40,408] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:29:40,428] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:44,709] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:29:44,994] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,994] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,995] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,995] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,995] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,995] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,997] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,998] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,998] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:44,999] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,000] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,000] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,001] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,002] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,002] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,003] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,004] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,004] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,008] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2c5529ab (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:45,024] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:29:45,031] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:45,035] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:45,044] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:45,046] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:45,049] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:58047, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:45,060] INFO Creating new log file: log.1b0 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-04-22 21:29:45,070] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005f01bc0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:45,076] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:45,194] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:29:45,273] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:29:45,383] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:29:45,384] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:29:45,402] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:29:45,405] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:45,411] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:29:45,516] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:29:45,534] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:29:45,584] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:45,596] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:45,599] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:45,601] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:45,661] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:45,666] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:29:45,753] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:45,755] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,756] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,760] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:45,761] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,799] INFO [ProducerStateManager partition=my-first-topic-0] Wrote producer snapshot at offset 4 with 0 producer ids in 9 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,857] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,857] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,860] INFO [ProducerStateManager partition=my-first-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,864] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,889] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-0, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 193ms (1/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:45,895] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:45,896] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,897] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,899] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:45,899] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,905] INFO [ProducerStateManager partition=my-first-topic-1] Wrote producer snapshot at offset 4 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,913] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,914] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,915] INFO [ProducerStateManager partition=my-first-topic-1] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,917] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,920] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-1, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 31ms (2/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:45,930] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:45,930] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,931] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,932] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:45,932] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,939] INFO [ProducerStateManager partition=my-first-topic-2] Wrote producer snapshot at offset 7 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,946] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,947] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,947] INFO [ProducerStateManager partition=my-first-topic-2] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot,7)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,950] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,953] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-2, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=7) with 1 segments in 33ms (3/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:45,962] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:45,963] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,963] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,965] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:45,965] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,971] INFO [ProducerStateManager partition=my-fisrt-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,979] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,979] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,980] INFO [ProducerStateManager partition=my-fisrt-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:45,982] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,985] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-fisrt-topic-0, topicId=u_QBLZWtQtSU7aAZPPbqqA, topic=my-fisrt-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 32ms (4/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:45,994] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:45,995] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,995] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:45,996] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:45,997] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,002] INFO [ProducerStateManager partition=my-second-topic-0] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,009] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,010] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,010] INFO [ProducerStateManager partition=my-second-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,012] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,016] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-second-topic-0, topicId=rbnejGrRQJCw5AB-qCDQNw, topic=my-second-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 30ms (5/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,023] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,024] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,027] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,028] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,034] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,034] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,035] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,038] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-0, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (6/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,043] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,044] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,044] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,045] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,051] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,051] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,052] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,055] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-1, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (7/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,062] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,062] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,063] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,063] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,069] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,070] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,070] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,074] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-10, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (8/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,078] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,079] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,079] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,080] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,087] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,087] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,090] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,094] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-11, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (9/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,098] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,098] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,099] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,099] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,106] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,106] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,107] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,111] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-12, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (10/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,119] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,120] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,122] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,123] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:46,123] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,150] INFO [ProducerStateManager partition=__consumer_offsets-13] Wrote producer snapshot at offset 831 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,157] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 831 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,158] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,159] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot,831)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,160] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,163] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-13, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=831) with 1 segments in 52ms (11/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,167] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,168] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,170] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,171] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,177] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,177] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,178] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,182] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-14, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (12/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,186] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,187] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,187] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,188] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,194] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,194] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,195] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,198] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-15, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (13/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,202] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,202] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,203] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,204] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,210] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,210] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,211] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,214] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-16, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (14/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,218] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,218] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,219] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,220] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,226] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,226] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,227] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,229] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-17, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (15/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,235] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,236] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,236] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,237] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,243] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,243] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,244] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,247] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-18, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (16/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,251] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,252] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,252] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,253] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,259] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,259] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,260] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,263] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-19, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (17/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,268] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,268] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,269] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,269] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,275] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,275] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,276] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,279] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-2, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (18/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,283] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,284] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,284] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,285] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,291] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,291] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,292] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,295] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-20, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (19/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,299] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,300] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,300] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,301] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,307] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,308] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,308] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,311] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-21, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (20/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,315] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,316] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,316] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,317] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,323] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,323] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,324] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,327] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-22, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (21/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,331] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,332] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,332] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,333] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,339] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,339] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,341] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,345] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-23, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (22/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,349] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,350] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,350] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,351] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,358] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,359] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,360] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,363] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-24, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (23/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,366] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,367] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,367] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,368] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,375] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,375] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,375] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,378] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-25, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (24/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,382] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,382] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,383] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,384] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,390] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,391] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,392] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,394] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-26, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (25/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,402] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,403] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,403] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,405] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:46,407] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,421] INFO [ProducerStateManager partition=__consumer_offsets-27] Wrote producer snapshot at offset 669 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,429] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 669 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,429] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,430] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot,669)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,432] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,434] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-27, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=669) with 1 segments in 39ms (26/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,437] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,439] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,439] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,440] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,446] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,447] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,448] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,450] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-28, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (27/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,454] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,455] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,456] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,456] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,463] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,463] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,464] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,466] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-29, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (28/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,470] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,471] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,472] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,473] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,478] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,479] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,479] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,482] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-3, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (29/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,486] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,487] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,487] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,488] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,494] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,494] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,495] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,498] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-30, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (30/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,502] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,503] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,504] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,504] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,510] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,511] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,511] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,514] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-31, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (31/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,518] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,519] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,520] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,520] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,527] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,527] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,528] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,530] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-32, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (32/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,539] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,540] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,540] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,542] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:46,542] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,547] INFO [ProducerStateManager partition=__consumer_offsets-33] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,554] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,554] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,555] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,557] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,559] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-33, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 29ms (33/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,563] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,565] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,565] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,566] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,572] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,573] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,573] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,576] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-34, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (34/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,581] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,581] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,582] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,582] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,587] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,588] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,588] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,591] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-35, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (35/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,595] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,596] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,596] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,597] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,603] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,604] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,604] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,607] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-36, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (36/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,611] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,612] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,613] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,613] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,620] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,620] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,621] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,623] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-37, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (37/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,627] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,628] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,628] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,629] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,635] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,635] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,636] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,639] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-38, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (38/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,643] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,644] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,645] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,646] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,651] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,652] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,652] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,655] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-39, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (39/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,659] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,659] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,660] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,660] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,666] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,667] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,667] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,670] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-4, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (40/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,673] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,675] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,675] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,676] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,682] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,682] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,683] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,685] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-40, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (41/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,689] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,691] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,691] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,692] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,698] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,698] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,699] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,701] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-41, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (42/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,704] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,708] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,708] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,709] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,715] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,715] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,716] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,718] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-42, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (43/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,722] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,723] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,723] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,724] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,730] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,731] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,732] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,734] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-43, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (44/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,737] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,739] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,739] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,740] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,746] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,746] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,747] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,749] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-44, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (45/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,752] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,753] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,755] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,756] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,762] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,763] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,763] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,765] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-45, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (46/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,769] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,771] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,771] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,772] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,778] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,778] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,779] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,781] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-46, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (47/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,784] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,786] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,787] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,788] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,794] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,794] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,795] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,797] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-47, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (48/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,800] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,802] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,802] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,803] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,809] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,809] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,810] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,812] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-48, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (49/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,815] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,818] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,819] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,820] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,824] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,826] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,826] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,828] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-49, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (50/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,833] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,834] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,835] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,836] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:29:46,836] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,841] INFO [ProducerStateManager partition=__consumer_offsets-5] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,848] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,848] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,849] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:29:46,851] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,852] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-5, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 24ms (51/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,856] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,856] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,857] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,858] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,864] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,864] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,865] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,867] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-6, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (52/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,870] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,871] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,871] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,872] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,878] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,880] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,881] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,883] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-7, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (53/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,886] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,887] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,887] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,888] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,894] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,895] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,895] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,898] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-8, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (54/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,901] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:29:46,902] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,902] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,903] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,910] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,911] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,911] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:29:46,913] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-9, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (55/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:29:46,916] INFO Loaded 55 logs in 1256ms. (kafka.log.LogManager)
[2022-04-22 21:29:46,917] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:29:46,918] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:29:47,281] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:47,414] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:29:47,420] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-04-22 21:29:47,451] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:29:47,460] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:47,486] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:47,488] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:47,488] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:47,491] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:47,508] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:29:49,644] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:29:49,975] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,975] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,975] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,976] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,976] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,976] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,978] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,979] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,979] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,980] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,980] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,981] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,982] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,982] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,983] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,984] INFO Client environment:os.memory.free=1009MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,984] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,985] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:49,988] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:50,003] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:29:50,011] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:50,014] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:50,023] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:50,025] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:50,029] INFO Socket connection established, initiating session, client: /127.0.0.1:58063, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:50,037] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100005f01bc0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:50,043] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:50,140] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:29:50,194] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:29:50,305] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:29:50,307] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:29:50,328] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:50,334] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:29:50,342] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:29:50,447] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:29:50,467] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:29:50,521] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:50,528] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:50,531] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:50,532] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:50,592] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-1) (kafka.log.LogManager)
[2022-04-22 21:29:50,598] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:29:50,615] INFO Loaded 0 logs in 22ms. (kafka.log.LogManager)
[2022-04-22 21:29:50,616] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:29:50,619] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:29:51,027] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:51,238] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:29:51,245] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-04-22 21:29:51,278] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:29:51,288] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:51,314] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:51,316] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:51,318] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:51,320] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:51,339] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:29:52,152] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:29:52,190] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72057991211581440' does not match current session '72058002088919040' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-04-22 21:29:52,198] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-04-22 21:29:52,202] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:29:52,204] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-04-22 21:29:52,209] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-04-22 21:29:52,217] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-04-22 21:29:52,218] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:29:52,219] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:29:52,219] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:29:52,221] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:29:52,222] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:29:52,223] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-04-22 21:29:52,225] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-04-22 21:29:52,225] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,421] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,421] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,425] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,612] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,612] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,615] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,628] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,628] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,631] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,836] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,836] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:52,847] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-04-22 21:29:52,848] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:52,849] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:52,849] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:52,857] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-04-22 21:29:52,858] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:52,859] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:52,859] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:52,862] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-04-22 21:29:52,863] INFO Shutting down. (kafka.log.LogManager)
[2022-04-22 21:29:53,032] INFO Shutdown complete. (kafka.log.LogManager)
[2022-04-22 21:29:53,032] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:29:53,034] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:29:53,034] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:29:53,037] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:53,145] INFO Session: 0x100005f01bc0000 closed (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:53,145] INFO EventThread shut down for session: 0x100005f01bc0000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:53,147] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:53,149] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:53,691] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:53,691] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:53,693] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:54,317] INFO Expiring session 0x100005b4ca10002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:54,318] INFO Expiring session 0x100005c79650002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:54,320] INFO Expiring session 0x100005c79650000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:29:54,694] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:54,694] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:54,697] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:54,897] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,898] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,899] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,899] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,899] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,900] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,904] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,904] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,905] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,906] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,907] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,908] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,909] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,910] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,910] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,911] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,913] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,917] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,921] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:29:54,939] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:29:54,948] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:54,952] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:54,962] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:54,964] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:54,968] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:58078, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:54,980] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100005f01bc0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:29:54,986] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:29:55,095] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:29:55,301] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:29:55,311] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:29:55,433] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:29:55,455] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:29:55,514] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,528] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,532] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,534] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,605] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-2) (kafka.log.LogManager)
[2022-04-22 21:29:55,612] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:29:55,633] INFO Loaded 0 logs in 28ms. (kafka.log.LogManager)
[2022-04-22 21:29:55,634] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:29:55,638] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:29:55,705] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,705] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,710] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:55,991] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:29:56,014] INFO Stat of the created znode at /brokers/ids/1 is: 482,482,1650637796005,1650637796005,1,0,0,72058002088919041,226,0,482
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:29:56,016] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9093, czxid (broker epoch): 482 (kafka.zk.KafkaZkClient)
[2022-04-22 21:29:56,081] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:56,101] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,109] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,110] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,133] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:29:56,152] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:29:56,178] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:29:56,184] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:29:56,185] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:29:56,239] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,270] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:29:56,317] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:29:56,329] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:29:56,331] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:29:56,340] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:29:56,343] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:29:56,346] INFO Kafka startTimeMs: 1650637796331 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:29:56,349] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-04-22 21:29:56,434] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:29:56,439] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:56,443] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-04-22 21:29:56,470] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:56,488] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:29:56,504] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:29:56,533] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,536] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,538] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,540] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:29:56,560] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:29:56,706] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:56,706] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:29:56,709] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-04-22 21:29:56,742] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-04-22 21:29:56,743] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:29:56,744] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:29:56,745] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-04-22 21:29:56,748] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-04-22 21:29:56,755] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:29:56,755] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-04-22 21:29:56,756] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-04-22 21:29:56,758] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-04-22 21:30:01,208] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:30:01,237] INFO Stat of the created znode at /brokers/ids/2 is: 540,540,1650637801224,1650637801224,1,0,0,72058002088919042,226,0,540
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:30:01,238] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9094, czxid (broker epoch): 540 (kafka.zk.KafkaZkClient)
[2022-04-22 21:30:01,342] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:30:01,352] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:30:01,355] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:30:01,380] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:30:01,400] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:30:01,429] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:30:01,435] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:30:01,436] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:30:01,485] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:30:01,509] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:30:01,541] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:30:01,548] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:30:01,549] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:30:01,557] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:30:01,558] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:30:01,559] INFO Kafka startTimeMs: 1650637801550 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:30:01,563] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-04-22 21:30:01,647] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:30:01,677] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:31:45,350] WARN Close of session 0x100005f01bc0003 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:32:15,317] INFO Expiring session 0x100005f01bc0003, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:32:26,251] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:32:26,802] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:32:26,907] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:32:26,908] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:32:26,929] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:32:31,532] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,869] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,869] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,870] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,870] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,870] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,873] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,874] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,874] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,875] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,876] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,876] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,877] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,878] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,878] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,879] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,880] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,881] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,884] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:32:39,903] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:32:39,911] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:32:39,916] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:32:39,927] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:32:39,929] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:32:39,933] INFO Socket connection established, initiating session, client: /127.0.0.1:56785, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:32:39,947] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100005f01bc0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:32:39,952] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:32:40,064] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:32:40,273] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:32:40,281] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:32:40,412] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:32:40,435] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:32:40,492] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:32:40,508] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:32:40,512] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:32:40,514] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:32:40,583] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,591] INFO Skipping recovery for all logs in D:\Kafka\kafka\data\kafka since clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:32:40,776] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,778] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,781] INFO [ProducerStateManager partition=my-first-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:40,792] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 14ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,836] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-0, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 199ms (1/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,852] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,852] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,854] INFO [ProducerStateManager partition=my-first-topic-1] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:40,855] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,862] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-1, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 24ms (2/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,876] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,876] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,878] INFO [ProducerStateManager partition=my-first-topic-2] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot,7)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:40,880] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,884] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-2, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=7) with 1 segments in 22ms (3/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,898] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,898] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,900] INFO [ProducerStateManager partition=my-fisrt-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:40,902] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,908] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-fisrt-topic-0, topicId=u_QBLZWtQtSU7aAZPPbqqA, topic=my-fisrt-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 24ms (4/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,922] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,922] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,924] INFO [ProducerStateManager partition=my-second-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:40,926] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,930] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-second-topic-0, topicId=rbnejGrRQJCw5AB-qCDQNw, topic=my-second-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 22ms (5/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,937] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,945] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-0, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (6/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,954] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,959] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-1, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (7/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,965] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,970] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-10, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,977] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,981] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-11, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:40,988] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:40,992] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-12, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (10/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,007] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 831 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,007] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,008] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot,831)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:41,009] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,013] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-13, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=831) with 1 segments in 21ms (11/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,020] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,024] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-14, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (12/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,031] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,034] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-15, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (13/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,041] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,044] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-16, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (14/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,051] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,054] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-17, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (15/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,061] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,065] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-18, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (16/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,073] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,076] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-19, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (17/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,083] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,086] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-2, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (18/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,094] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,097] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-20, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (19/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,104] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,107] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-21, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (20/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,114] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,117] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-22, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (21/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,124] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,127] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-23, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (22/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,133] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,136] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-24, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (23/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,142] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,146] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-25, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (24/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,153] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,156] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-26, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (25/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,169] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 669 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,170] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,171] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot,669)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:41,173] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,175] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-27, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=669) with 1 segments in 18ms (26/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,182] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,185] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-28, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (27/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,192] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,196] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-29, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (28/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,202] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,205] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-3, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (29/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,212] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,215] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-30, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (30/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,221] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,225] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-31, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (31/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,233] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,236] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-32, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (32/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,248] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,249] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,250] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:41,251] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,254] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-33, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 18ms (33/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,261] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,263] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-34, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (34/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,269] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,273] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-35, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (35/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,280] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,282] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-36, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (36/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,289] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,292] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-37, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (37/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,298] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,301] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-38, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (38/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,309] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,312] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-39, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (39/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,318] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,322] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-4, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (40/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,328] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,331] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-40, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (41/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,337] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,340] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-41, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (42/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,347] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,350] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-42, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (43/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,358] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,360] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-43, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (44/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,367] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,370] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-44, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (45/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,376] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,379] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-45, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (46/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,385] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,387] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-46, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (47/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,393] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,395] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-47, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (48/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,403] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,405] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-48, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (49/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,411] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,415] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-49, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (50/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,427] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,428] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,429] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:32:41,430] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,433] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-5, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 18ms (51/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,440] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,445] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-6, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (52/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,450] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,452] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-7, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (53/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,458] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,461] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-8, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (54/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,467] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:32:41,468] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-9, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (55/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:32:41,472] INFO Loaded 55 logs in 888ms. (kafka.log.LogManager)
[2022-04-22 21:32:41,474] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:32:41,476] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:32:41,844] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:32:41,982] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:32:41,988] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-04-22 21:32:42,021] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:32:42,030] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:32:42,056] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:42,059] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:42,059] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:42,061] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:42,078] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:32:46,716] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:32:46,744] INFO Stat of the created znode at /brokers/ids/0 is: 558,558,1650637966730,1650637966730,1,0,0,72058002088919044,226,0,558
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:32:46,746] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9092, czxid (broker epoch): 558 (kafka.zk.KafkaZkClient)
[2022-04-22 21:32:46,896] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:46,905] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:46,907] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:46,930] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:46,947] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:46,981] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:32:46,988] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:32:46,988] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:32:47,036] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:32:47,072] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:32:47,123] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:32:47,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:32:47,136] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:32:47,147] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:32:47,148] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:32:47,149] INFO Kafka startTimeMs: 1650637967136 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:32:47,156] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-04-22 21:32:47,280] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:32:47,310] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:32:47,331] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,332] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,334] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,335] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,336] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,337] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,338] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,339] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,340] INFO [Partition my-first-topic-2 broker=0] Log loaded for partition my-first-topic-2 with initial high watermark 7 (kafka.cluster.Partition)
[2022-04-22 21:32:47,342] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,345] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,346] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,347] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,349] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,349] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,351] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,351] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,352] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Partition)
[2022-04-22 21:32:47,353] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,355] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,356] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,357] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,361] INFO [Partition my-fisrt-topic-0 broker=0] Log loaded for partition my-fisrt-topic-0 with initial high watermark 1 (kafka.cluster.Partition)
[2022-04-22 21:32:47,363] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 669 (kafka.cluster.Partition)
[2022-04-22 21:32:47,363] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,364] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,365] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,366] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 3 (kafka.cluster.Partition)
[2022-04-22 21:32:47,367] INFO [Partition my-first-topic-0 broker=0] Log loaded for partition my-first-topic-0 with initial high watermark 4 (kafka.cluster.Partition)
[2022-04-22 21:32:47,369] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,369] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,370] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,371] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,372] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,375] INFO [Partition my-second-topic-0 broker=0] Log loaded for partition my-second-topic-0 with initial high watermark 2 (kafka.cluster.Partition)
[2022-04-22 21:32:47,379] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,380] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,380] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,381] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,382] INFO [Partition my-first-topic-1 broker=0] Log loaded for partition my-first-topic-1 with initial high watermark 4 (kafka.cluster.Partition)
[2022-04-22 21:32:47,384] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,384] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,385] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,386] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,386] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,387] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,388] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,389] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,394] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,395] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,397] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,397] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,399] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,400] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:32:47,401] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 831 (kafka.cluster.Partition)
[2022-04-22 21:32:47,448] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, my-second-topic-0, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, my-fisrt-topic-0, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, my-first-topic-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, my-first-topic-2, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, my-first-topic-1, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:32:47,645] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,648] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,651] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,651] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,652] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,653] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,654] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,655] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,656] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,657] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,658] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,659] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,659] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,660] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,661] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,661] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 12 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,665] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,667] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,667] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 15 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,667] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,669] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 15 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,669] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,670] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,670] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,672] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 14 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,672] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,673] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 14 milliseconds for epoch 4, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,674] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,675] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 14 milliseconds for epoch 4, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,675] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,677] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,680] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,682] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,683] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,682] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 13 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,684] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,685] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 13 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,685] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,686] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,686] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,688] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 6 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,690] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,691] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,691] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,696] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 6 milliseconds for epoch 4, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,697] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,698] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,698] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,699] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,700] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds for epoch 4, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,701] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,702] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,703] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,704] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,704] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,706] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,707] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,712] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,712] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,713] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,714] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,715] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,716] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,717] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,717] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,718] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,719] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,720] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,720] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,721] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,722] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,723] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,729] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,729] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,730] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,731] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,732] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,733] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,734] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,734] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,735] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,736] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,737] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,737] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,739] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,741] INFO Loaded member MemberMetadata(memberId=console-consumer-2ea4b850-b99e-40be-b52c-d81b3bb1d42a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,743] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,745] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,746] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,747] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,747] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,748] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,749] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,749] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,750] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,751] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,751] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,752] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,753] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,753] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,754] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,758] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,759] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,759] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,760] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,760] INFO Loaded member MemberMetadata(memberId=console-consumer-341e2672-61f6-4e3d-90ca-ad1834dc410e, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,761] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,762] INFO Loaded member MemberMetadata(memberId=console-consumer-2ea4b850-b99e-40be-b52c-d81b3bb1d42a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,762] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,763] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,764] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,764] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,765] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,766] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,766] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,767] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,767] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,771] INFO Loaded member MemberMetadata(memberId=console-consumer-341e2672-61f6-4e3d-90ca-ad1834dc410e, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,776] INFO Loaded member MemberMetadata(memberId=console-consumer-af370b12-03a2-4453-bdd7-ee2bd75a61bc, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,785] INFO [GroupCoordinator 0]: Loading group metadata for my-first-app with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 88 milliseconds for epoch 4, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 87 milliseconds for epoch 4, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,792] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 87 milliseconds for epoch 4, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,793] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 81 milliseconds for epoch 4, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,796] INFO Loaded member MemberMetadata(memberId=console-consumer-b7ed5905-bf7f-4515-b7d4-81a2e8d11554, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-45122 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 85 milliseconds for epoch 4, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 83 milliseconds for epoch 4, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 83 milliseconds for epoch 4, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,800] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 82 milliseconds for epoch 4, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 82 milliseconds for epoch 4, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 80 milliseconds for epoch 4, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 79 milliseconds for epoch 4, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 74 milliseconds for epoch 4, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 73 milliseconds for epoch 4, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,807] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 75 milliseconds for epoch 4, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,808] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 74 milliseconds for epoch 4, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,808] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 73 milliseconds for epoch 4, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,809] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 72 milliseconds for epoch 4, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 71 milliseconds for epoch 4, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,810] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 65 milliseconds for epoch 4, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 64 milliseconds for epoch 4, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,812] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 64 milliseconds for epoch 4, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,812] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 63 milliseconds for epoch 4, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,813] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 62 milliseconds for epoch 4, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,814] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 62 milliseconds for epoch 4, of which 62 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,814] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 61 milliseconds for epoch 4, of which 61 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,818] INFO Loaded member MemberMetadata(memberId=console-consumer-3d3ebe95-d5db-4582-b0db-577c0131baf8, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-second-app with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,819] INFO Loaded member MemberMetadata(memberId=console-consumer-24d030c2-59fc-4002-bcdb-1ba10eb26cb9, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-second-app with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,826] INFO [GroupCoordinator 0]: Loading group metadata for my-second-app with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:32:47,826] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 68 milliseconds for epoch 4, of which 57 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,827] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 68 milliseconds for epoch 4, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,831] INFO Loaded member MemberMetadata(memberId=console-consumer-05fc5b3f-7e86-4581-af95-f32bf52a57d0, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-24592 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:32:47,832] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 71 milliseconds for epoch 4, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,832] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 69 milliseconds for epoch 4, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,833] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 69 milliseconds for epoch 4, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 68 milliseconds for epoch 4, of which 68 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 67 milliseconds for epoch 4, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:47,835] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 67 milliseconds for epoch 4, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:32:56,897] WARN Close of session 0x100005f01bc0005 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:01,818] WARN Close of session 0x100005f01bc0004 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:12,011] WARN Close of session 0x100005f01bc0006 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:18,317] INFO Expiring session 0x100005f01bc0004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:33:21,915] WARN Close of session 0x100005f01bc0007 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:24,071] WARN Close of session 0x100005f01bc0001 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:27,205] WARN Close of session 0x100005f01bc0002 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:27,317] INFO Expiring session 0x100005f01bc0005, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:33:36,798] WARN Close of session 0x100005f01bc0008 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:39,317] INFO Expiring session 0x100005f01bc0001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:33:42,317] INFO Expiring session 0x100005f01bc0006, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:33:45,279] WARN Close of session 0x100005f01bc0009 (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:45,316] INFO Expiring session 0x100005f01bc0002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:33:53,992] WARN Close of session 0x100005f01bc000a (org.apache.zookeeper.server.NIOServerCnxn)
java.io.IOException: An existing connection was forcibly closed by the remote host
	at java.base/sun.nio.ch.SocketDispatcher.read0(Native Method)
	at java.base/sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:43)
	at java.base/sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:276)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:245)
	at java.base/sun.nio.ch.IOUtil.read(IOUtil.java:223)
	at java.base/sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:358)
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:324)
	at org.apache.zookeeper.server.NIOServerCnxnFactory$IOWorkRequest.doWork(NIOServerCnxnFactory.java:522)
	at org.apache.zookeeper.server.WorkerService$ScheduledWorkRequest.run(WorkerService.java:154)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
[2022-04-22 21:33:54,318] INFO Expiring session 0x100005f01bc0007, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:34:06,319] INFO Expiring session 0x100005f01bc0008, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:34:15,331] INFO Expiring session 0x100005f01bc0009, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:34:24,317] INFO Expiring session 0x100005f01bc000a, timeout of 30000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,532] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,534] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,546] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,546] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,546] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,547] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,549] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:35:23,549] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:35:23,549] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-04-22 21:35:23,550] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-04-22 21:35:23,554] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-04-22 21:35:23,569] INFO Reading configuration from: ..\..\config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,569] WARN ..\..\config\zookeeper.properties is relative. Prepend .\ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,570] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,570] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,571] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,571] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-04-22 21:35:23,571] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-04-22 21:35:23,584] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@3d1cfad4 (org.apache.zookeeper.server.ServerMetrics)
[2022-04-22 21:35:23,589] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:35:23,600] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,601] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,604] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,605] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,605] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,606] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,607] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,607] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,608] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:23,609] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,164] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,165] INFO Server environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,167] INFO Server environment:java.version=11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,168] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,169] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,171] INFO Server environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,173] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,174] INFO Server environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,175] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,176] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,176] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,177] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,178] INFO Server environment:user.name=thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,178] INFO Server environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,179] INFO Server environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,183] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,184] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,185] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,186] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,187] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,188] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,188] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,189] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,190] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,191] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,193] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-04-22 21:35:28,195] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,196] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,199] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:35:28,199] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-04-22 21:35:28,202] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:35:28,202] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:35:28,203] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:35:28,204] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:35:28,205] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:35:28,206] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-04-22 21:35:28,210] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,211] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,212] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir D:\Kafka\kafka\data\zookeeper\version-2 snapdir D:\Kafka\kafka\data\zookeeper\version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,239] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:35:28,241] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-04-22 21:35:28,244] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 24 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:35:28,250] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-04-22 21:35:28,285] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:35:28,286] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-04-22 21:35:28,291] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:35:28,291] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:35:28,298] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-04-22 21:35:28,307] INFO Reading snapshot D:\Kafka\kafka\data\zookeeper\version-2\snapshot.1af (org.apache.zookeeper.server.persistence.FileSnap)
[2022-04-22 21:35:28,318] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x1af, and digest value as 313946948505 (org.apache.zookeeper.server.DataTree)
[2022-04-22 21:35:28,351] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-04-22 21:35:28,378] INFO 252 txns loaded in 40 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:35:28,379] INFO Snapshot loaded in 86 ms, highest zxid is 0x2ab, digest is 288069968803 (org.apache.zookeeper.server.ZKDatabase)
[2022-04-22 21:35:28,380] INFO Snapshotting: 0x2ab to D:\Kafka\kafka\data\zookeeper\version-2\snapshot.2ab (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-04-22 21:35:28,387] INFO Snapshot taken in 8 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-04-22 21:35:28,403] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-04-22 21:35:28,404] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-04-22 21:35:28,426] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-04-22 21:35:34,260] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:35:34,273] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:35:34,295] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-04-22 21:35:34,865] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:35:34,869] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:35:34,889] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-04-22 21:35:35,011] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:35:35,012] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:35:35,014] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:35:35,015] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:35:35,034] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:35,036] INFO starting (kafka.server.KafkaServer)
[2022-04-22 21:35:35,037] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:35,038] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-04-22 21:35:35,058] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,603] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,603] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,603] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,604] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,604] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,605] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,604] INFO Client environment:host.name=SD-LT-0201.SAI-IT.COM (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,605] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,605] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,605] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,605] INFO Client environment:java.version=11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,605] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,606] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,606] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,606] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.12 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,606] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,606] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,606] INFO Client environment:java.class.path=D:\Kafka\kafka\libs\activation-1.1.1.jar;D:\Kafka\kafka\libs\aopalliance-repackaged-2.6.1.jar;D:\Kafka\kafka\libs\argparse4j-0.7.0.jar;D:\Kafka\kafka\libs\audience-annotations-0.5.0.jar;D:\Kafka\kafka\libs\commons-cli-1.4.jar;D:\Kafka\kafka\libs\commons-lang3-3.8.1.jar;D:\Kafka\kafka\libs\connect-api-3.1.0.jar;D:\Kafka\kafka\libs\connect-basic-auth-extension-3.1.0.jar;D:\Kafka\kafka\libs\connect-file-3.1.0.jar;D:\Kafka\kafka\libs\connect-json-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-3.1.0.jar;D:\Kafka\kafka\libs\connect-mirror-client-3.1.0.jar;D:\Kafka\kafka\libs\connect-runtime-3.1.0.jar;D:\Kafka\kafka\libs\connect-transforms-3.1.0.jar;D:\Kafka\kafka\libs\hk2-api-2.6.1.jar;D:\Kafka\kafka\libs\hk2-locator-2.6.1.jar;D:\Kafka\kafka\libs\hk2-utils-2.6.1.jar;D:\Kafka\kafka\libs\jackson-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-core-2.12.3.jar;D:\Kafka\kafka\libs\jackson-databind-2.12.3.jar;D:\Kafka\kafka\libs\jackson-dataformat-csv-2.12.3.jar;D:\Kafka\kafka\libs\jackson-datatype-jdk8-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-base-2.12.3.jar;D:\Kafka\kafka\libs\jackson-jaxrs-json-provider-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-jaxb-annotations-2.12.3.jar;D:\Kafka\kafka\libs\jackson-module-scala_2.12-2.12.3.jar;D:\Kafka\kafka\libs\jakarta.activation-api-1.2.1.jar;D:\Kafka\kafka\libs\jakarta.annotation-api-1.3.5.jar;D:\Kafka\kafka\libs\jakarta.inject-2.6.1.jar;D:\Kafka\kafka\libs\jakarta.validation-api-2.0.2.jar;D:\Kafka\kafka\libs\jakarta.ws.rs-api-2.1.6.jar;D:\Kafka\kafka\libs\jakarta.xml.bind-api-2.3.2.jar;D:\Kafka\kafka\libs\javassist-3.27.0-GA.jar;D:\Kafka\kafka\libs\javax.servlet-api-3.1.0.jar;D:\Kafka\kafka\libs\javax.ws.rs-api-2.1.1.jar;D:\Kafka\kafka\libs\jaxb-api-2.3.0.jar;D:\Kafka\kafka\libs\jersey-client-2.34.jar;D:\Kafka\kafka\libs\jersey-common-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-2.34.jar;D:\Kafka\kafka\libs\jersey-container-servlet-core-2.34.jar;D:\Kafka\kafka\libs\jersey-hk2-2.34.jar;D:\Kafka\kafka\libs\jersey-server-2.34.jar;D:\Kafka\kafka\libs\jetty-client-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-continuation-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-http-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-io-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-security-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-server-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlet-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-servlets-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jetty-util-ajax-9.4.43.v20210629.jar;D:\Kafka\kafka\libs\jline-3.12.1.jar;D:\Kafka\kafka\libs\jopt-simple-5.0.4.jar;D:\Kafka\kafka\libs\jose4j-0.7.8.jar;D:\Kafka\kafka\libs\kafka-clients-3.1.0.jar;D:\Kafka\kafka\libs\kafka-log4j-appender-3.1.0.jar;D:\Kafka\kafka\libs\kafka-metadata-3.1.0.jar;D:\Kafka\kafka\libs\kafka-raft-3.1.0.jar;D:\Kafka\kafka\libs\kafka-server-common-3.1.0.jar;D:\Kafka\kafka\libs\kafka-shell-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-3.1.0.jar;D:\Kafka\kafka\libs\kafka-storage-api-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-examples-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-scala_2.12-3.1.0.jar;D:\Kafka\kafka\libs\kafka-streams-test-utils-3.1.0.jar;D:\Kafka\kafka\libs\kafka-tools-3.1.0.jar;D:\Kafka\kafka\libs\kafka_2.12-3.1.0.jar;D:\Kafka\kafka\libs\log4j-1.2.17.jar;D:\Kafka\kafka\libs\lz4-java-1.8.0.jar;D:\Kafka\kafka\libs\maven-artifact-3.8.1.jar;D:\Kafka\kafka\libs\metrics-core-2.2.0.jar;D:\Kafka\kafka\libs\metrics-core-4.1.12.1.jar;D:\Kafka\kafka\libs\netty-buffer-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-codec-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-handler-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-resolver-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-epoll-4.1.68.Final.jar;D:\Kafka\kafka\libs\netty-transport-native-unix-common-4.1.68.Final.jar;D:\Kafka\kafka\libs\osgi-resource-locator-1.0.3.jar;D:\Kafka\kafka\libs\paranamer-2.8.jar;D:\Kafka\kafka\libs\plexus-utils-3.2.1.jar;D:\Kafka\kafka\libs\reflections-0.9.12.jar;D:\Kafka\kafka\libs\rocksdbjni-6.22.1.1.jar;D:\Kafka\kafka\libs\scala-collection-compat_2.12-2.4.4.jar;D:\Kafka\kafka\libs\scala-java8-compat_2.12-1.0.0.jar;D:\Kafka\kafka\libs\scala-library-2.12.14.jar;D:\Kafka\kafka\libs\scala-logging_2.12-3.9.3.jar;D:\Kafka\kafka\libs\scala-reflect-2.12.14.jar;D:\Kafka\kafka\libs\slf4j-api-1.7.30.jar;D:\Kafka\kafka\libs\slf4j-log4j12-1.7.30.jar;D:\Kafka\kafka\libs\snappy-java-1.1.8.4.jar;D:\Kafka\kafka\libs\trogdor-3.1.0.jar;D:\Kafka\kafka\libs\zookeeper-3.6.3.jar;D:\Kafka\kafka\libs\zookeeper-jute-3.6.3.jar;D:\Kafka\kafka\libs\zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,612] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,613] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,611] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.12\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;C:\oraclexe\app\oracle\product\11.2.0\server\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files\Git\cmd;C:\Program Files\TortoiseGit\bin;C:\Program Files\Java\jdk-11.0.12\bin;C:\Users\thai.pham\flutter\bin;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files\Microsoft SQL Server\150\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files\Azure Data Studio\bin;C:\Program Files\Docker\Docker\resources\bin;C:\ProgramData\DockerDesktop\version-bin;C:\Program Files\nodejs\;C:\Users\username\AppData\Roaming\npm;C:\Program Files\Java\apache-maven-3.8.5\bin;C:\Users\thai.pham\AppData\Local\Microsoft\WindowsApps;C:\Users\thai.pham\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\thai.pham\AppData\Roaming\npm;C:\Users\thai.pham\AppData\Roaming\nvm;C:\Program Files\nodejs;C:\Program Files\Azure Data Studio\bin;D:\;;. (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,617] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,617] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,618] INFO Client environment:java.io.tmpdir=C:\Users\THAI~1.PHA\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,634] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,634] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,635] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,638] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,640] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,642] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,641] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,645] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,646] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,646] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,647] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,650] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,651] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,652] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,656] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,657] INFO Client environment:user.name=thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,661] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,662] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,663] INFO Client environment:user.home=C:\Users\thai.pham (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,663] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,664] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,667] INFO Client environment:user.dir=D:\Kafka\kafka\bin\windows (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,669] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,670] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,676] INFO Client environment:os.memory.free=1010MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,678] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,678] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,679] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,686] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,684] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,689] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,692] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,697] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6492fab5 (org.apache.zookeeper.ZooKeeper)
[2022-04-22 21:35:39,715] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:35:39,715] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:35:39,722] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-04-22 21:35:39,726] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,726] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,731] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,732] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,732] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,737] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,747] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,748] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,749] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,750] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,750] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,752] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,757] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:59432, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,760] INFO Socket connection established, initiating session, client: /127.0.0.1:59433, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,761] INFO Socket connection established, initiating session, client: /127.0.0.1:59434, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,776] INFO Creating new log file: log.2ac (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-04-22 21:35:39,795] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100006467690000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,795] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x100006467690001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,795] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100006467690002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-04-22 21:35:39,805] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,806] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,806] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-04-22 21:35:39,953] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:35:39,954] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:35:39,954] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-04-22 21:35:40,188] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:35:40,198] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:35:40,203] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:35:40,204] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-04-22 21:35:40,216] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:35:40,217] INFO Cluster ID = OFLVqWaGR_qjCIrtWyV6GQ (kafka.server.KafkaServer)
[2022-04-22 21:35:40,357] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:35:40,372] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:35:40,378] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:35:40,383] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:35:40,400] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:35:40,412] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = D:/Kafka/kafka/data/kafka-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-04-22 21:35:40,477] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,481] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,485] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,488] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,491] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,494] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,495] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,486] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,497] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,499] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,501] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,504] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-04-22 21:35:40,576] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-1) (kafka.log.LogManager)
[2022-04-22 21:35:40,583] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka-2) (kafka.log.LogManager)
[2022-04-22 21:35:40,587] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka-1 since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:35:40,592] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka-2 since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:35:40,594] INFO Loading logs from log dirs ArrayBuffer(D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:40,603] INFO Attempting recovery for all logs in D:\Kafka\kafka\data\kafka since no clean shutdown file was found (kafka.log.LogManager)
[2022-04-22 21:35:40,614] INFO Loaded 0 logs in 37ms. (kafka.log.LogManager)
[2022-04-22 21:35:40,616] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:35:40,616] INFO Loaded 0 logs in 33ms. (kafka.log.LogManager)
[2022-04-22 21:35:40,620] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:35:40,625] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:35:40,623] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:35:40,738] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:40,742] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,745] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,749] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:40,752] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,799] INFO [ProducerStateManager partition=my-first-topic-0] Wrote producer snapshot at offset 4 with 0 producer ids in 7 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:40,879] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,879] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,883] INFO [ProducerStateManager partition=my-first-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-0\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:40,887] INFO [LogLoader partition=my-first-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,919] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-0, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 278ms (1/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:40,927] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:40,928] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,928] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,930] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:40,930] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,937] INFO [ProducerStateManager partition=my-first-topic-1] Wrote producer snapshot at offset 4 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:40,946] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 4 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,947] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,948] INFO [ProducerStateManager partition=my-first-topic-1] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-1\00000000000000000004.snapshot,4)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:40,951] INFO [LogLoader partition=my-first-topic-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 4 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,957] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-1, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=4) with 1 segments in 36ms (2/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:40,971] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:40,973] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,974] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,975] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:40,976] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,985] INFO [ProducerStateManager partition=my-first-topic-2] Wrote producer snapshot at offset 7 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:40,995] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 7 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,995] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:40,996] INFO [ProducerStateManager partition=my-first-topic-2] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-first-topic-2\00000000000000000007.snapshot,7)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,000] INFO [LogLoader partition=my-first-topic-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 7 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,006] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-first-topic-2, topicId=iCBuFACxTRKBgEOdCf4Jmw, topic=my-first-topic, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=7) with 1 segments in 49ms (3/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,017] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,018] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,020] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,021] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:41,022] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,029] INFO [ProducerStateManager partition=my-fisrt-topic-0] Wrote producer snapshot at offset 1 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,039] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 1 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,039] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,040] INFO [ProducerStateManager partition=my-fisrt-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-fisrt-topic-0\00000000000000000001.snapshot,1)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,043] INFO [LogLoader partition=my-fisrt-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 1 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,048] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-fisrt-topic-0, topicId=u_QBLZWtQtSU7aAZPPbqqA, topic=my-fisrt-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1) with 1 segments in 42ms (4/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,061] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,062] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,062] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,064] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:41,065] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,074] INFO [ProducerStateManager partition=my-second-topic-0] Wrote producer snapshot at offset 2 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,082] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 2 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,082] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,083] INFO [ProducerStateManager partition=my-second-topic-0] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\my-second-topic-0\00000000000000000002.snapshot,2)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,087] INFO [LogLoader partition=my-second-topic-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 4ms for snapshot load and 0ms for segment recovery from offset 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,091] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\my-second-topic-0, topicId=rbnejGrRQJCw5AB-qCDQNw, topic=my-second-topic, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=2) with 1 segments in 41ms (5/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,099] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,100] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,101] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,101] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,109] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,109] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,110] INFO [LogLoader partition=__consumer_offsets-0, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,114] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-0, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (6/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,120] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,121] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,121] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,122] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,129] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,131] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,133] INFO [LogLoader partition=__consumer_offsets-1, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,139] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-1, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (7/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,149] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,150] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,150] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,151] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,157] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,159] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,160] INFO [LogLoader partition=__consumer_offsets-10, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,166] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-10, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (8/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,173] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,174] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,174] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,175] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,182] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,183] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,184] INFO [LogLoader partition=__consumer_offsets-11, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,188] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-11, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (9/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,194] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,195] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,196] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,197] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,204] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:41,204] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,205] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:41,204] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,207] INFO [LogLoader partition=__consumer_offsets-12, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,214] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-12, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 25ms (10/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,223] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,223] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,224] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,225] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:41,227] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,256] INFO [ProducerStateManager partition=__consumer_offsets-13] Wrote producer snapshot at offset 831 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,265] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 831 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,266] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,267] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-13\00000000000000000831.snapshot,831)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,270] INFO [LogLoader partition=__consumer_offsets-13, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 831 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,274] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-13, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=831) with 1 segments in 59ms (11/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,279] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,280] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,281] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,282] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,290] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,291] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,292] INFO [LogLoader partition=__consumer_offsets-14, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,296] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-14, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (12/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,302] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,303] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,304] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,305] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,316] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,316] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,317] INFO [LogLoader partition=__consumer_offsets-15, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,323] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-15, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (13/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,331] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,332] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,332] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,333] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,342] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,343] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,344] INFO [LogLoader partition=__consumer_offsets-16, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,349] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-16, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (14/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,354] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,355] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,356] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,357] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,367] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,367] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,370] INFO [LogLoader partition=__consumer_offsets-17, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,375] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-17, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (15/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,381] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,382] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,382] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,383] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,393] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,393] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,394] INFO [LogLoader partition=__consumer_offsets-18, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,400] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-18, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (16/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,410] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,411] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,412] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,413] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,424] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,425] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,426] INFO [LogLoader partition=__consumer_offsets-19, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,431] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-19, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 29ms (17/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,441] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,442] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,442] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,443] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,454] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,455] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,456] INFO [LogLoader partition=__consumer_offsets-2, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,460] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-2, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (18/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,467] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,469] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,470] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,471] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,481] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,482] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,483] INFO [LogLoader partition=__consumer_offsets-20, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,488] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-20, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 27ms (19/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,497] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,499] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,499] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,500] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,511] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,513] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,514] INFO [LogLoader partition=__consumer_offsets-21, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,519] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-21, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 30ms (20/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,525] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,526] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,526] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,527] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,534] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:35:41,540] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,540] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,541] INFO [LogLoader partition=__consumer_offsets-22, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,543] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-04-22 21:35:41,546] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-22, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 26ms (21/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,549] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:35:41,552] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,553] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,554] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,554] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,557] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-04-22 21:35:41,564] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,564] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,566] INFO [LogLoader partition=__consumer_offsets-23, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,571] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-23, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (22/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,576] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,577] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,577] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,578] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,587] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,587] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,589] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:35:41,588] INFO [LogLoader partition=__consumer_offsets-24, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,593] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-24, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 21ms (23/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,599] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,600] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,600] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,601] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,604] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:41,608] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:35:41,610] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,611] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,612] INFO [LogLoader partition=__consumer_offsets-25, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,615] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-25, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (24/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,620] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,621] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:41,622] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,623] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,624] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,632] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,632] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,633] INFO [LogLoader partition=__consumer_offsets-26, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,638] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-26, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (25/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,640] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,643] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,644] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,646] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,649] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,650] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,651] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,654] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:41,655] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,658] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,661] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,663] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,664] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:41,671] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:35:41,672] INFO [ProducerStateManager partition=__consumer_offsets-27] Wrote producer snapshot at offset 669 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,681] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 669 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,682] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,684] INFO [ProducerStateManager partition=__consumer_offsets-27] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-27\00000000000000000669.snapshot,669)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,688] INFO [LogLoader partition=__consumer_offsets-27, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 5ms for snapshot load and 0ms for segment recovery from offset 669 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,688] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:35:41,691] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-27, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=669) with 1 segments in 53ms (26/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,695] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,696] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,697] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,697] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,705] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,705] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,706] INFO [LogLoader partition=__consumer_offsets-28, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,709] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-28, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (27/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,712] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,713] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,715] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,716] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,722] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,722] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,723] INFO [LogLoader partition=__consumer_offsets-29, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,725] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-29, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (28/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,730] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,731] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,732] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,733] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,739] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,739] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,740] INFO [LogLoader partition=__consumer_offsets-3, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,742] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-3, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (29/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,746] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,747] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,747] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,748] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,755] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,755] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,756] INFO [LogLoader partition=__consumer_offsets-30, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,759] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-30, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (30/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,765] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,765] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,765] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,766] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,773] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,773] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,774] INFO [LogLoader partition=__consumer_offsets-31, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,776] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-31, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (31/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,781] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,782] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,782] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,783] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,790] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,790] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,791] INFO [LogLoader partition=__consumer_offsets-32, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,796] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-32, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (32/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,805] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,805] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,806] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,807] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:41,808] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,816] INFO [ProducerStateManager partition=__consumer_offsets-33] Wrote producer snapshot at offset 3 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,824] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,824] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,825] INFO [ProducerStateManager partition=__consumer_offsets-33] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-33\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:41,827] INFO [LogLoader partition=__consumer_offsets-33, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,829] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-33, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 33ms (33/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,833] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,834] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,834] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,836] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,843] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,844] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,844] INFO [LogLoader partition=__consumer_offsets-34, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,847] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-34, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (34/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,851] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,852] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,853] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,853] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,861] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,862] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,863] INFO [LogLoader partition=__consumer_offsets-35, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,865] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-35, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (35/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,869] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,872] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,873] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,874] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,881] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,882] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,883] INFO [LogLoader partition=__consumer_offsets-36, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,888] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-36, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 22ms (36/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,894] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,894] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,894] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,896] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,903] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,903] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,904] INFO [LogLoader partition=__consumer_offsets-37, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,907] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-37, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (37/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,910] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,911] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,911] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,912] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,919] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,919] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,921] INFO [LogLoader partition=__consumer_offsets-38, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,923] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-38, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (38/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,927] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,928] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,928] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,929] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,937] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,937] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,938] INFO [LogLoader partition=__consumer_offsets-39, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,940] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-39, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (39/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,944] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,944] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,945] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,946] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,953] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,953] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,955] INFO [LogLoader partition=__consumer_offsets-4, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,957] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-4, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (40/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,961] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,961] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,962] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,962] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,969] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,969] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,970] INFO [LogLoader partition=__consumer_offsets-40, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,973] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-40, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (41/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,977] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,977] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,978] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,978] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,984] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,984] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,986] INFO [LogLoader partition=__consumer_offsets-41, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,989] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-41, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (42/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:41,993] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:41,993] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,994] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:41,995] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 1ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,003] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,003] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,004] INFO [LogLoader partition=__consumer_offsets-42, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,006] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-42, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (43/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,010] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,011] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,013] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,014] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,020] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,020] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,021] INFO [LogLoader partition=__consumer_offsets-43, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,023] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-43, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (44/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,027] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,029] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,029] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,030] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,036] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,036] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,037] INFO [LogLoader partition=__consumer_offsets-44, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,039] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-44, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (45/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,043] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,044] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,044] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,045] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,051] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,051] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,052] INFO [LogLoader partition=__consumer_offsets-45, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,055] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-45, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (46/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,059] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,060] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,061] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,062] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,067] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,068] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,069] INFO [LogLoader partition=__consumer_offsets-46, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,071] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-46, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (47/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,074] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,076] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,077] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,078] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,084] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,084] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,085] INFO [LogLoader partition=__consumer_offsets-47, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,088] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-47, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (48/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,091] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,092] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,093] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,093] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,099] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,099] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,100] INFO [LogLoader partition=__consumer_offsets-48, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,102] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-48, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (49/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,106] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,108] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,108] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,109] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,115] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,115] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,116] INFO [LogLoader partition=__consumer_offsets-49, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,118] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-49, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (50/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,123] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,124] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,124] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,126] INFO Deleted producer state snapshot D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-04-22 21:35:42,126] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,131] INFO [ProducerStateManager partition=__consumer_offsets-5] Wrote producer snapshot at offset 3 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-04-22 21:35:42,138] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,139] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,140] INFO [ProducerStateManager partition=__consumer_offsets-5] Loading producer state from snapshot file 'SnapshotFile(D:\Kafka\kafka\data\kafka\__consumer_offsets-5\00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-04-22 21:35:42,142] INFO [LogLoader partition=__consumer_offsets-5, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,144] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-5, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 25ms (51/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,147] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,148] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,148] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,149] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,155] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,156] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,157] INFO [LogLoader partition=__consumer_offsets-6, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,159] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-6, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (52/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,163] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,163] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,164] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,164] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,171] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,172] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,173] INFO [LogLoader partition=__consumer_offsets-7, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,175] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-7, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (53/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,178] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,179] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,179] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,180] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,186] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,188] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,189] INFO [LogLoader partition=__consumer_offsets-8, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,191] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-8, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (54/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,195] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Recovering unflushed segment 0 (kafka.log.LogLoader$)
[2022-04-22 21:35:42,195] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,196] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,196] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,203] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,205] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,205] INFO [LogLoader partition=__consumer_offsets-9, dir=D:\Kafka\kafka\data\kafka] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2022-04-22 21:35:42,207] INFO Completed load of Log(dir=D:\Kafka\kafka\data\kafka\__consumer_offsets-9, topicId=mvZN4uyZR2yiAWjyUoE5YQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (55/55 loaded in D:\Kafka\kafka\data\kafka) (kafka.log.LogManager)
[2022-04-22 21:35:42,209] INFO Loaded 55 logs in 1616ms. (kafka.log.LogManager)
[2022-04-22 21:35:42,211] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-04-22 21:35:42,212] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-04-22 21:35:42,581] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:42,721] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-04-22 21:35:42,726] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-04-22 21:35:42,761] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:35:42,771] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:42,796] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:42,798] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:42,798] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:42,801] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:42,816] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-04-22 21:35:46,321] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:46,324] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:46,358] INFO Stat of the created znode at /brokers/ids/1 is: 730,730,1650638146345,1650638146345,1,0,0,72058025269592066,226,0,730
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:46,359] INFO Stat of the created znode at /brokers/ids/2 is: 729,729,1650638146344,1650638146344,1,0,0,72058025269592065,226,0,729
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:46,361] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9093, czxid (broker epoch): 730 (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:46,361] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9094, czxid (broker epoch): 729 (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:46,463] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,466] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,472] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,475] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,479] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,481] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,509] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:46,514] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:46,548] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:46,555] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:46,602] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:35:46,610] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:35:46,615] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:35:46,615] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:35:46,621] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:35:46,621] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:35:46,693] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,694] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:46,733] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:35:46,741] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:35:46,799] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:35:46,806] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:35:46,815] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:35:46,818] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:35:46,831] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:35:46,833] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:35:46,837] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:46,841] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:46,846] INFO Kafka startTimeMs: 1650638146819 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:46,851] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-04-22 21:35:46,856] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:46,856] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:46,860] INFO Kafka startTimeMs: 1650638146836 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:46,866] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-04-22 21:35:47,001] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:47,031] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:47,095] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:47,139] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:47,429] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:47,454] INFO Stat of the created znode at /brokers/ids/0 is: 789,789,1650638147442,1650638147442,1,0,0,72058025269592064,226,0,789
 (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:47,456] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://SD-LT-0201.SAI-IT.COM:9092, czxid (broker epoch): 789 (kafka.zk.KafkaZkClient)
[2022-04-22 21:35:47,574] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:47,584] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:47,586] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:47,608] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:47,630] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:47,652] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:35:47,657] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-04-22 21:35:47,657] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-04-22 21:35:47,697] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-04-22 21:35:47,720] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-04-22 21:35:47,750] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:35:47,756] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-04-22 21:35:47,757] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-04-22 21:35:47,763] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:47,763] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:47,764] INFO Kafka startTimeMs: 1650638147757 (org.apache.kafka.common.utils.AppInfoParser)
[2022-04-22 21:35:47,767] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-04-22 21:35:47,850] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:47,909] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,910] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,912] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,914] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,914] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,915] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,916] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,916] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,917] INFO [Partition my-first-topic-2 broker=0] Log loaded for partition my-first-topic-2 with initial high watermark 7 (kafka.cluster.Partition)
[2022-04-22 21:35:47,918] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,919] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,919] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,920] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,921] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,922] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,923] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,924] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,924] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 3 (kafka.cluster.Partition)
[2022-04-22 21:35:47,925] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,926] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,926] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,927] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker SD-LT-0201.SAI-IT.COM:9094 (id: 2 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-04-22 21:35:47,927] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,931] INFO [Partition my-fisrt-topic-0 broker=0] Log loaded for partition my-fisrt-topic-0 with initial high watermark 1 (kafka.cluster.Partition)
[2022-04-22 21:35:47,932] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 669 (kafka.cluster.Partition)
[2022-04-22 21:35:47,933] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,933] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,934] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,934] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 3 (kafka.cluster.Partition)
[2022-04-22 21:35:47,935] INFO [Partition my-first-topic-0 broker=0] Log loaded for partition my-first-topic-0 with initial high watermark 4 (kafka.cluster.Partition)
[2022-04-22 21:35:47,936] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,936] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,937] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,938] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,938] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,939] INFO [Partition my-second-topic-0 broker=0] Log loaded for partition my-second-topic-0 with initial high watermark 2 (kafka.cluster.Partition)
[2022-04-22 21:35:47,939] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,940] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,941] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,941] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,942] INFO [Partition my-first-topic-1 broker=0] Log loaded for partition my-first-topic-1 with initial high watermark 4 (kafka.cluster.Partition)
[2022-04-22 21:35:47,942] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,943] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,947] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,947] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,948] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,949] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,949] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,950] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,950] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,951] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,952] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,952] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,953] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,953] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:35:47,954] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 831 (kafka.cluster.Partition)
[2022-04-22 21:35:47,991] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, my-second-topic-0, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, my-fisrt-topic-0, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, my-first-topic-0, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, my-first-topic-2, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, my-first-topic-1, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:35:48,159] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,161] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,163] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 25 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,163] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,164] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,164] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,165] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 31 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,166] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,167] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,167] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,168] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 37 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,169] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,169] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,170] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,170] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 8 milliseconds for epoch 7, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,171] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 43 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,172] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,172] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 8 milliseconds for epoch 7, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,173] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,174] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,174] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 9 milliseconds for epoch 7, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,174] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 49 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,176] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,175] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 7, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,176] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,177] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,177] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 9 milliseconds for epoch 7, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,178] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 44 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,179] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 10 milliseconds for epoch 7, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,179] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,180] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 9 milliseconds for epoch 7, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,183] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,184] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 11 milliseconds for epoch 7, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,185] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,186] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 12 milliseconds for epoch 7, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,186] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 1 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,187] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,187] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 11 milliseconds for epoch 7, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,188] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,189] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 7, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,189] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,190] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 7 milliseconds for epoch 7, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,190] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 7 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,192] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,191] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 5 milliseconds for epoch 7, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,192] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,193] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 5 milliseconds for epoch 7, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,194] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,195] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 5 milliseconds for epoch 7, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,195] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 13 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,196] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 4 milliseconds for epoch 7, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,200] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,201] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 6 milliseconds for epoch 7, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,202] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 19 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,203] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,204] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 2 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,205] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,206] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,207] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 14 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,208] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,209] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 20 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,211] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,215] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,215] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 26 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,216] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,217] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,218] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 8 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,218] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,219] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,219] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,220] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 38 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,221] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,221] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 32 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,222] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,222] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 0 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,223] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,223] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,224] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,225] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 6 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,225] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,226] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,226] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,227] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 12 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,232] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,234] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 18 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,234] INFO Loaded member MemberMetadata(memberId=console-consumer-2ea4b850-b99e-40be-b52c-d81b3bb1d42a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,235] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,236] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,237] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,238] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 24 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,238] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,239] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,239] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,240] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 30 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,241] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,241] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,242] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,243] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 36 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,246] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,247] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,247] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,248] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 42 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,249] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,249] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,250] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,250] INFO Loaded member MemberMetadata(memberId=console-consumer-341e2672-61f6-4e3d-90ca-ad1834dc410e, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,251] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 48 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,252] INFO Loaded member MemberMetadata(memberId=console-consumer-2ea4b850-b99e-40be-b52c-d81b3bb1d42a, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,252] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,262] INFO Loaded member MemberMetadata(memberId=console-consumer-341e2672-61f6-4e3d-90ca-ad1834dc410e, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,264] INFO Loaded member MemberMetadata(memberId=console-consumer-af370b12-03a2-4453-bdd7-ee2bd75a61bc, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-first-app with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,274] INFO [GroupCoordinator 0]: Loading group metadata for my-first-app with generation 5 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,281] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 80 milliseconds for epoch 7, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,281] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 79 milliseconds for epoch 7, of which 79 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,282] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 78 milliseconds for epoch 7, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,283] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 78 milliseconds for epoch 7, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,286] INFO Loaded member MemberMetadata(memberId=console-consumer-b7ed5905-bf7f-4515-b7d4-81a2e8d11554, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-45122 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,287] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 81 milliseconds for epoch 7, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,288] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 81 milliseconds for epoch 7, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,289] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 81 milliseconds for epoch 7, of which 80 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,292] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 83 milliseconds for epoch 7, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,292] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 82 milliseconds for epoch 7, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 78 milliseconds for epoch 7, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,294] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 78 milliseconds for epoch 7, of which 78 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,295] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 78 milliseconds for epoch 7, of which 77 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,295] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 76 milliseconds for epoch 7, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 76 milliseconds for epoch 7, of which 76 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 75 milliseconds for epoch 7, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 75 milliseconds for epoch 7, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,298] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 74 milliseconds for epoch 7, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,298] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 73 milliseconds for epoch 7, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 73 milliseconds for epoch 7, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,299] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 72 milliseconds for epoch 7, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,300] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 69 milliseconds for epoch 7, of which 69 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,301] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 67 milliseconds for epoch 7, of which 67 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,301] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 65 milliseconds for epoch 7, of which 65 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,302] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 64 milliseconds for epoch 7, of which 64 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,303] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 64 milliseconds for epoch 7, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,306] INFO Loaded member MemberMetadata(memberId=console-consumer-3d3ebe95-d5db-4582-b0db-577c0131baf8, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-second-app with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,309] INFO Loaded member MemberMetadata(memberId=console-consumer-24d030c2-59fc-4002-bcdb-1ba10eb26cb9, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group my-second-app with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,313] INFO [GroupCoordinator 0]: Loading group metadata for my-second-app with generation 3 (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:35:48,314] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 74 milliseconds for epoch 7, of which 63 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,315] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 74 milliseconds for epoch 7, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,319] INFO Loaded member MemberMetadata(memberId=console-consumer-05fc5b3f-7e86-4581-af95-f32bf52a57d0, groupInstanceId=None, clientId=console-consumer, clientHost=/172.26.208.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-24592 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-04-22 21:35:48,319] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 76 milliseconds for epoch 7, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,320] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 73 milliseconds for epoch 7, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,321] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 73 milliseconds for epoch 7, of which 72 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,324] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 75 milliseconds for epoch 7, of which 75 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,325] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 74 milliseconds for epoch 7, of which 74 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:35:48,326] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 72 milliseconds for epoch 7, of which 71 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-04-22 21:36:33,288] INFO [GroupCoordinator 0]: Member console-consumer-af370b12-03a2-4453-bdd7-ee2bd75a61bc in group my-first-app has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:36:33,295] INFO [GroupCoordinator 0]: Preparing to rebalance group my-first-app in state PreparingRebalance with old generation 5 (__consumer_offsets-13) (reason: removing member console-consumer-af370b12-03a2-4453-bdd7-ee2bd75a61bc on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:36:33,300] INFO [GroupCoordinator 0]: Group my-first-app with generation 6 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:36:33,372] INFO [GroupCoordinator 0]: Member console-consumer-24d030c2-59fc-4002-bcdb-1ba10eb26cb9 in group my-second-app has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:36:33,372] INFO [GroupCoordinator 0]: Preparing to rebalance group my-second-app in state PreparingRebalance with old generation 3 (__consumer_offsets-27) (reason: removing member console-consumer-24d030c2-59fc-4002-bcdb-1ba10eb26cb9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:36:33,377] INFO [GroupCoordinator 0]: Group my-second-app with generation 4 is now empty (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:55:49,071] INFO Creating topic new-kafka-topic with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-04-22 21:55:49,113] INFO [Controller id=2, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-04-22 21:55:49,113] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-04-22 21:55:49,113] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-04-22 21:55:49,124] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(new-kafka-topic-0) (kafka.server.ReplicaFetcherManager)
[2022-04-22 21:55:49,135] INFO [LogLoader partition=new-kafka-topic-0, dir=D:\Kafka\kafka\data\kafka] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-04-22 21:55:49,140] INFO Created log for partition new-kafka-topic-0 in D:\Kafka\kafka\data\kafka\new-kafka-topic-0 with properties {} (kafka.log.LogManager)
[2022-04-22 21:55:49,144] INFO [Partition new-kafka-topic-0 broker=0] No checkpointed highwatermark is found for partition new-kafka-topic-0 (kafka.cluster.Partition)
[2022-04-22 21:55:49,145] INFO [Partition new-kafka-topic-0 broker=0] Log loaded for partition new-kafka-topic-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-04-22 21:57:57,350] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-55339 in Empty state. Created a new member id console-consumer-5a2b289d-7351-4000-b7e4-02bcf3b3c8d6 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:57:57,358] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-55339 in state PreparingRebalance with old generation 0 (__consumer_offsets-36) (reason: Adding new member console-consumer-5a2b289d-7351-4000-b7e4-02bcf3b3c8d6 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:57:57,363] INFO [GroupCoordinator 0]: Stabilized group console-consumer-55339 generation 1 (__consumer_offsets-36) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:57:57,381] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-5a2b289d-7351-4000-b7e4-02bcf3b3c8d6 for group console-consumer-55339 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:41,536] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-55339 in state PreparingRebalance with old generation 1 (__consumer_offsets-36) (reason: Removing member console-consumer-5a2b289d-7351-4000-b7e4-02bcf3b3c8d6 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:41,537] INFO [GroupCoordinator 0]: Group console-consumer-55339 with generation 2 is now empty (__consumer_offsets-36) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:41,542] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=console-consumer-5a2b289d-7351-4000-b7e4-02bcf3b3c8d6, groupInstanceId=None, clientId=console-consumer, clientHost=/172.29.96.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-55339 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:47,022] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-82395 in Empty state. Created a new member id console-consumer-7bbec234-e11f-405d-b640-086bb8455598 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:47,026] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-82395 in state PreparingRebalance with old generation 0 (__consumer_offsets-8) (reason: Adding new member console-consumer-7bbec234-e11f-405d-b640-086bb8455598 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:47,027] INFO [GroupCoordinator 0]: Stabilized group console-consumer-82395 generation 1 (__consumer_offsets-8) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:47,037] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-7bbec234-e11f-405d-b640-086bb8455598 for group console-consumer-82395 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:53,096] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-82395 in state PreparingRebalance with old generation 1 (__consumer_offsets-8) (reason: Removing member console-consumer-7bbec234-e11f-405d-b640-086bb8455598 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:53,097] INFO [GroupCoordinator 0]: Group console-consumer-82395 with generation 2 is now empty (__consumer_offsets-8) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:58:53,101] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=console-consumer-7bbec234-e11f-405d-b640-086bb8455598, groupInstanceId=None, clientId=console-consumer, clientHost=/172.29.96.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-82395 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:04,096] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group console-consumer-49118 in Empty state. Created a new member id console-consumer-fd724dc3-7895-4ccd-ab91-0f812fae526b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:04,100] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-49118 in state PreparingRebalance with old generation 0 (__consumer_offsets-44) (reason: Adding new member console-consumer-fd724dc3-7895-4ccd-ab91-0f812fae526b with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:04,101] INFO [GroupCoordinator 0]: Stabilized group console-consumer-49118 generation 1 (__consumer_offsets-44) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:04,111] INFO [GroupCoordinator 0]: Assignment received from leader console-consumer-fd724dc3-7895-4ccd-ab91-0f812fae526b for group console-consumer-49118 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:06,395] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-49118 in state PreparingRebalance with old generation 1 (__consumer_offsets-44) (reason: Removing member console-consumer-fd724dc3-7895-4ccd-ab91-0f812fae526b on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:06,396] INFO [GroupCoordinator 0]: Group console-consumer-49118 with generation 2 is now empty (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2022-04-22 21:59:06,400] INFO [GroupCoordinator 0]: Member MemberMetadata(memberId=console-consumer-fd724dc3-7895-4ccd-ab91-0f812fae526b, groupInstanceId=None, clientId=console-consumer, clientHost=/172.29.96.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-49118 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
